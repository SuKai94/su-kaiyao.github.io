<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>SuKai</title>
    <link href="" rel="self" />
    <link href="http://sukai.me/" />
    <updated>2016-08-24T21:00:00Z</updated>
    <id>http://sukai.me/</id>
    
    <entry>
        <title><![CDATA[Face Alignment Summary]]></title>
        <author><name>SuKai</name><uri>http://sukai.me/</uri></author>
        <link href="http://sukai.me/face-alignment-summary/"/>
        <updated>2016-08-24T21:00:00Z</updated>
        <published>2016-08-24T21:00:00Z</published>
        <id>http://sukai.me/face-alignment-summary/</id>
        <content type="html">
            <![CDATA[
             <p>以我目前所读论文为依据，现有算法大体上分为两种类型：  </p>

<ul>
<li>1. Classifying Search Windows<br/></li>
<li>2. Directly Predict Key Point Positions（or Shape Parameters）<br/></li>
</ul>

<p>暂时没有接触第一种category的paper，第二种还可以细分为两种：  </p>

<ul>
<li>1. 基于模型（Model Based），代表有AAM、ASM<br/></li>
<li>2. 基于回归（Regression Based）。还可以细分为基于线性回归的，代表有CPR, LBF等；基于非线性回归的，代表有DCNN、CFAN、TDA等<br/></li>
</ul>

<p>对每个paper我关注以下几点：  </p>

<ul>
<li>属于那种框架或模型：基于Model？Cascaded（级联）模型？基于Deep Learning的非线性回归模型？等等<br/></li>
<li>优缺点：算法的Speed、Accuracy；是否利用特征点之间的相对位置关系（Geometric/Shape Constraints）以增强鲁棒性；对Occlusion、Pose Variations、Lighting的是够敏感<br/></li>
<li>Feature是如何提取的，使用的是Local Feature还是Global Feature<br/></li>
</ul>

<h3>Model Based</h3>

<p>基于模型的论文都对人脸建立了一定的模型，也是论文的核心idea，较为出名的模型有：AAM模型、ASM模型、CLM模型。它们提出的模型可以刻画出人脸图像，所以只需要求得特定人脸对应的模型参数（即Directly Predict Shape Parameters），即可合成相应的人脸图像  </p>

<p>ASM（Active Shape Model）是一种基于点分布模型（Point Distribution Model）的算法，AAM（Active Appearance Model）则在ASM基础上，进一步对纹理进行建模，并将形状和纹理两个统计模型进一步融合为表观模型。其中ASM为每个特征点构建局部特征，AAM则使用全局纹理信息  </p>

<p>AAM模型拟合过程如下：  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/AAM.png" alt=""/>  </p>

<p>基于模型的方法难点在于人脸模型的建立，而且对初始值很敏感，鲁棒性不高  </p>

<p>这方面论文大都在1998年左右发表，只看了4篇，理解不多，就简略介绍  </p>

<h3>Regression Based</h3>

<p>该方法尝试学习 从Deteced Face Region 到 Facial Landmarks的 Mapping，有基于线性和非线性Regressor的两种方案  </p>

<h4>1.线性Regressor</h4>

<p>1.1 Cascaded Pose Regression（CVPR 10）  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/CPR.png" alt=""/>  </p>

<p>级联回归模型在CVPR 10首次提出。它的核心思想是学习多个回归器，每个回归器预测当前形状和真实形状之间的偏差（也叫增量），然后将偏差合成（想加）到当前形状，形成新的预测形状，作为下一个回归器的输入，从而逐步逼近真实值  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/CPR-Test.png" alt=""/>  </p>

<p>每个回归器均不一样，需要预先提取特征，作为回归器的输入，特征采用Pose-Indexed Features（不是很理解特征提取这方面，懂的人可以告知本人，不胜感激），也可以使用SIFT、HOG等人工设计的特征；回归函数采用Random Fern Regressors  </p>

<p>CPR有明显的缺点：其对初始化形状非常敏感，论文中使用K次不同的初始化形状来测试，并融合K次的测试结果作为最终预测形状。而且CPR不能有效解决Occlusion问题  </p>

<p>CPR出现后，之后的回归模型算法大都基于级联框架，统一称作级联回归模型，只是不同的级联回归算法使用的Regressor和特征不同，别的基本一致，所以级联框架的提出算是Face Alignment发展史的伟大一步  </p>

<p>1.2 Face Alignment by Expicit Shape Regression（CVPR 12）  </p>

<p>论文设计了Two-Level Boosted Regression增强了鲁棒性，使用Correlation-Based Feature Selection方案来提取Shape Indexed Feature，大大提高了时间效率  </p>

<p>Two-Level Boosted Regression具体是指：External-level和Internal-level，即boosted regression和two level cascaded的结合。其中最原始的回归器r基于Random Fern学习  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/ESR.png" alt=""/>  </p>

<p>而且，论文注意到形状约束的重要性。它认为只有那些显著的特征点（眼睛中心、嘴巴边缘）可以由image appearance可靠地得到，其余不显著的Landmarks需要使用特征点间的shape constraint进行约束。先前的工作如ASM、AAM利用参数化的形状模型（PCA）来强制这种约束，而本文则抛弃不灵活的固定模型，使用boosted regression，使得shape constraint adaptively enforced from coarse to fine，论文的结论是最终的shape是初始形状和所有训练形状的线性组合，只要初始形状满足形状约束，得到的regressed shapa在由所有训练的shape构成的线性子空间中也满足形状约束（具体证明见论文），所以和之间预先固定的PCA shape model相比，论文非参数化的形状约束adaptively determined  </p>

<p>1.3 Using Conditional Regression Forests（CVPR 12）  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/CRF.png" alt=""/>  </p>

<p>论文不同于基于Regression Forest的方法，它的核心是基于Conditional Regression Forests。一般基于Regression Forest学习到facial image patches和location of feature points之间的mapping，而conditional regression forest则基于face image的某些属性预先进行分类，然后基于特定分类下的regression forest学习相应的mapping  </p>

<p>如图，可以依据head pose将图片分为5种Label：profile left；left；front；right；profile right  </p>

<p>1.4 Robust Face Landmark estimation under occlusion（ICCV 13）  </p>

<p>又名：Robust Cascaded Pose Regression（RCPR），旨在解决CPR的遮挡问题，它在预测landmarks的同时预测特征点被遮挡的状态  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/RCPR.png" alt=""/>  </p>

<p>同时RCPR对CPR的初始化敏感问题也提出了改进，即智能重启：随机初始化一组形状，运行至级联模型的前10%回归器，统计形状预测的方差，如果方差小于一定阈值，说明这组初始化不错，则跑完剩下的90%的级联函数，得到最终的预测结果；如果方差大于一定阈值，则说明初始化不理想，选择重新初始化一组形状  </p>

<p>1.5 DRMF（CVPR 13）  </p>

<p>论文首先用Constrained Local Models（CLM模型）对人脸进行建模。之后DRMF利用SVR对回归器建模，并使用HOG特征（相对的有：SIFT特征）最为回归函数的输入，最终预测出CLM的人脸模型参数，而不是直接预测人脸的形状。由于模型很难刻画出完整的人脸变化形状，所以鲁棒性欠缺  </p>

<p>1.6 Regressing Local Binary Features（CVPR 14）  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/LBF2.png" alt=""/>  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/LBF1.png" alt=""/>  </p>

<p>如图，LBF使用了Random Forest作预测，但LBF并没有直接采用随机树中叶子节点存储的形变量作为最终预测结果，而是将输出组成二值化特征（LBF），再利用这个LBF来作最终的形变预测  </p>

<p>总的来说，LBF方法第一步为每个landmark独立建立随机森林，形成各自的Local Binary Feature；然后连接所有的LBF作全局线性回归（这样可以有效利用关键点间的约束信息）得到最终形变量。其中第一步基于random forest学习得到Feature Mapping需要使用到shape indexed feature，也因为LBF非常稀疏，所以计算速度很快  </p>

<p>1.7 Supervised Descent Method  </p>

<p>SDM将Face Alignment看作非线性最小二乘问题。通常求解非线性最小二乘问题可以通过二阶的牛顿法解决，然而在computer vision任务中，某些函数不一定可微，而且Hessian矩阵位维数很大且不一定正定，所以论文提出了SDM算法来最小化非线性最小二乘函数，即以监督学习方式求解梯度方向  </p>

<p>在训练阶段，SDM学习每个特征点的非线性最小二乘函数的梯度方向，组成梯度序列。之后测试阶段，就可以直接使用学习好的梯度方向来最小化非线性最小二乘函数，从而避免直接计算Jacobian或Hessian矩阵  </p>

<p>通过论文可以发现，因此需要学习一组梯度序列，该方法属于级联回归模型  </p>

<p>1.8 Face Alignment with an Ensemble of Regression Trees（CVPR 14）  </p>

<p>论文基于集成回归树学习从input image到landmarks的映射；而且论文为image中每个landmark引入权重W可以解决训练数据标记缺失的问题  </p>

<h4>2.非线性Regressor：利用CNN进行非线性建模（级联卷积神经网络）</h4>

<p>2.1 CUHK的DCNN（CVPR 13）提出了3层框架  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/DCNN.png" alt="DCNN"/>  </p>

<p>第一层使用整个face image作为input region（所以特征是global high-level feature），得到了initial predicitons，所以该层为initialization stage。而且该层同时进行不同key points的预测，所以能有效利用geometric constraints  </p>

<p>之后的二三层对第一层的结果进行refine，每层的cnn以当前预测点为中心，提取local feature，预测出当前facial points和ground truth之间的偏差  </p>

<p>可以看出DCNN采用coarse-to-fine的步骤，一步一步逼近ground truth，因此也属于cascaded（级联）模型  </p>

<p>2.2 CFAN（ECCV 14）  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/CFAN.png" alt=""/>  </p>

<p>与DCNN类似，也是coarse-to-fine的级联模型，第一个CNN预测出初始值，后面的CNN用于refine从而逼近真实值。DCNN二三层是对第一层初始结果的refine，使用没有shape constraint的local features，因此容易得到局部最优值，对occlusion等影响因素的鲁棒性不理想。CFAN解决了这个问题，在同样的第一层处理之后，之后的每层使用point之间的约束信息（constraint），因此CFAN对第一步init值的敏感度要比DCNN低。另外，CFAN的每层的input image的分辨率逐渐提高，第一步用于快速的预测初始值，低分辨率的图片对应于large search step，后面紧跟的refine用作局部调整，则选择使用高分辨率的image作为input  </p>

<p>2.3 TDA（ACCV 14）  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/TDA.png" alt=""/>  </p>

<p>TDA与DCNN、CFAN大体类似，其不同之处是先根据Face Image的Topic进行分类，然后使用每个分类下独立特有的CNN网络进行处理  </p>

<p>这里的Topic分类是指通过k-means clustering对人脸图片进行分类，来决定人脸图片属于5中Topic中的哪一类，以决定之后使用某具体分类下的CNN网络。和级联回归模型中的Conditional Regression Forests（利用face image的head pose对face进行分类）想法类似  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/TDA-Topic-Aware.png" alt=""/>  </p>

<p>可以看出上面三种级联深度模型都将Image To Shape的mapping分解到级联框架的各个stage分别进行训练或处理，而且基于CNN对非线性映射进行建模，也免于特征的手动提取  </p>

<h3>References</h3>

<ul>
<li><a href="http://www.cnblogs.com/gavin-vision/p/4829016.html" target="_blank">Cascade Pose Regression</a><br/></li>
<li><a href="http://blog.csdn.net/santo_wong_94/article/details/49330295" target="_blank">阅读Face Alignment by Explicit Shape Regression</a><br/></li>
<li><a href="http://blog.luoyetx.com/2015/08/face-alignment-at-3000fps/" target="_blank">Face Alignment at 3000 FPS via Regressing Local Binary Features</a><br/></li>
<li><a href="http://chuansong.me/n/290740451748" target="_blank">深度大讲堂：面部特征点定位概述及最近研究进展</a><br/></li>
</ul>

<p>历时1个月多一点的时间，总共读了约15篇paper。大多数paper都在8月初就完成了阅读，拖到现在才整理也是因为自己懒惰。作为CV和ML新手，以及阅读相隔时间较长，文章不免会有许多理解上的错误🤖</p>

            ]]>
        </content>
    </entry>
    
    <entry>
        <title><![CDATA[2016暑期总结]]></title>
        <author><name>SuKai</name><uri>http://sukai.me/</uri></author>
        <link href="http://sukai.me/2016-summer/"/>
        <updated>2016-07-30T12:00:00Z</updated>
        <published>2016-07-30T12:00:00Z</published>
        <id>http://sukai.me/2016-summer/</id>
        <content type="html">
            <![CDATA[
             <h3>7月</h3>

<p><strong>工作</strong>  </p>

<ul>
<li>7月看了10 ~ 11篇论文（Face Alignment），这占据了工作的大部分时间。目前从宏观上了解了相关算法的研究“轨迹”及分类。但对于某些论文，顺着作者的文字无法理解相关算法的细节，大概是自己基础知识太薄弱了，扣出细节的部分就会云里雾里。并没有本质性突破，离自己提出某个idea并作出实验还很远很远，也为自己比较担心<br/></li>
<li>组会，7月开了两次的组会。第一次师兄教了MatConvNet的使用，这是师兄们去年参加CVPR Face Age Estimation比赛的代码，听说当时拿了不错的名次，还因此出国参加了CVPR16（👍）。不过惭愧，本人由于没有实践反馈，半个多月下来基本忘了是个怎么回事儿了=..=<br/></li>
<li>第二次，师兄介绍了比赛中Face Image的预处理过程，使用的是CUHK的<a href="http://mmlab.ie.cuhk.edu.hk/archive/CNN_FacePoint.htm" target="_blank">Five Facial Point Detection</a>。这和我的关系非常大，因为不出意外我研一进入实验室后会研究Face Alignment<br/></li>
<li>几天之后的某次实验，我采用该方法对实验数据进行预处理，当初觉得手上有了一些源代码，应该没啥难度，但由于开源代码软件的一些坑，还有对Matlab的不熟悉，需要用Matlab写一个脚本，然后吭哧吭哧跑了20h实验，花了三天才完全做完预处理实验。实验过程中觉得Matlab这门编程语言太重了，太依赖ide，不过之后肯定需要学习并熟悉下Matlab了。还有一个非常不错的远程控制软件TeamViewr，提高了我的工作效率<br/></li>
</ul>

<p><strong>读书</strong>  </p>

<ul>
<li>《算法 4Th》的1 ~ 4章，全书就要看完了，还剩两章。书虽然厚，但除去算法的数学证明外至少都不难啃，读起来还算轻松<br/></li>
<li>《自控力》<br/></li>
</ul>

<p>这个月的时间可能被工作划去了大部分，读书时间投入不多，其实说到底还是自己不重视阅读这个环节，加上自己的懒癌  </p>

<p><strong>学习</strong>  </p>

<ul>
<li>阅读些Deep Learning和Convolutional Nerual Networks相关的Paper和Tutorial<br/></li>
<li>在Lintcode、hihocoder上撸了一些题<br/></li>
<li>为了比较Cpython和PyPy，寻找答案的过程中，发现最省事最靠谱的方式就是Wikipedia和Stackoverflow<br/></li>
</ul>

<p><strong>生活</strong>  </p>

<p>基本白天都是一个人在家，也试着给生活找了点乐趣：  </p>

<ul>
<li>掌握了几道家常菜：番茄蛋汤、红烧肉、蚝油生菜、可乐鸡翅等，厨艺只是停留在靠油盐酱醋等佐料辅助的水平上<br/></li>
<li>7月下半旬，又开始玩起三国杀<br/></li>
<li>每周两次，每次30-60分钟的运动<br/></li>
</ul>

<h3>8月</h3>

<p><strong>工作</strong>  </p>

<ul>
<li>Google Face Image爬虫。没有写这个爬虫前算是小看这个Project的难度了，这个Project最大的难点是GFW。Google被墙，要想让JVM强制走sock5，我采用的方案是Proxifier和Shadowsocks的结合，当然事情还没那么简单，GFW将Google.com的DNS污染了，所以使用Proxifier时候要选择让Proxy Server自主DNS解析，这边也不得不佩服GFW。还有一个小难点是Https，我使用Java的Httpclient，默认模拟Https（Http）请求时，Httpclient默认自动加上SSL层，节省了我的编程的时间。至于寻找图片下拉刷新的Ajax Url，通过Chrome调试窗口的Network（本来还想用WireShark，无奈不会用，也没那个必要）就可以找到了，这点不难。最终代码托管在Github上：<a href="https://github.com/su-kaiyao/googleFaceImageSpider" target="_blank">googleFaceImageSpider</a>。当然啦，我的爬虫是通用的，只要指定搜索Image的关键词就可以了，还可以指定爬多少张，也可以指定线程池大小和线程数量，以提高速度<br/></li>
<li>回顾了上个月阅读的11篇论文<br/></li>
<li>阅读3 ~ 4篇新论文（Face Alignment）<br/></li>
</ul>

<p><strong>学习</strong>  </p>

<ul>
<li>发现了一篇讲述生动的<a href="http://blog.jobbole.com/70549/" target="_blank">“ 傅里叶变换 ”</a>文章<br/></li>
<li>读了Alexnet的论文，其中的trick有：Training on multiple GPUs, Local Response Normalization, Overlapping Pooling, Dropout<br/></li>
<li>读了有关CNN的文章，都收藏在了我Blog的Deep Learning Wikis中<br/></li>
<li><a href="http://blog.csdn.net/zouxy09/article/details/24971995" title="L0 L1 L2" target="_blank">L0、L1与L2范数规则化</a>，<a href="http://blog.csdn.net/shiwei408/article/details/7602324" title="distance" target="_blank">机器学习中的各种距离</a><br/></li>
<li>算法Trick：位操作很强大，可以用作枚举排列组合；Python中的itertools.combinations也可以快速生成排列<br/></li>
<li>虽然很久之前就开始了解<a href="https://en.wikipedia.org/wiki/C10k_problem" title="L0 L1 L2" target="_blank">C10k Problem</a>，当时使用过Java的NIO、Netty。最近看了Node.js相关的文章，对于C10k Problem又有了些研究兴趣。宏观上的理解还是当初的那个印象：传统的解决方案是多进程多线程模型，即One Connection，One Thread，大量（10k）条进程（或线程）的创建和调度会造成OS很大的资源消耗。后来有了IO多路复用模型，select到poll再到epoll，孕育出很多杰作（Tornado、Node.js）等等。另一种解决方案则是协程，将内核从繁重的调度任务中解放出来，典型的代表是Go语言。暂时了解的还不够透彻，之后有空再进一步研究<br/></li>
</ul>

<p><strong>读书</strong>  </p>

<ul>
<li>《算法4th》读完了。后面两章比前面四章难啃，尤其是字符串这章，内容对我来说都很新<br/></li>
<li>《写作这回事：创作生涯回忆录》<br/></li>
<li>《时间管理：如何充分利用你的24小时》<br/></li>
<li>《娱乐至死》<br/></li>
<li>《乖，摸摸头》<br/></li>
<li>《沥川往事》<br/></li>
</ul>

<p>这个月读的另外三本书都不胃口，记住的句子和观点也很少，有的并不值得读  </p>

<p><strong>生活</strong>  </p>

<p>这个月总得来说，过得很松  </p>

<ul>
<li>将Blog的Analysis切换到了Google Analysis<br/></li>
<li>重新装上LOL，玩了3 ~ 4天又将其卸载<br/></li>
<li>这个月看了不少电影😜：《驯龙高手Ⅰ&amp;Ⅱ》、《夏洛特烦恼》、《火影：博人转》、《我是传奇》、《使徒行者》、《寒战Ⅱ》、《他是龙》、《X战警：天启》。最喜欢的是《驯龙高手Ⅰ&amp;Ⅱ》，在豆瓣里是Top 250的影片<br/></li>
<li>一首“歌”真的能激活头脑中的回忆神经，夜晚在工作台放着大四在宿舍经常放的歌曲，能回忆很多大四宿舍的生活场景，能闻到宿舍熟悉的味道<br/></li>
</ul>

<p>8月待续  </p>

<h3>反馈</h3>

<p><strong>信噪比</strong>  </p>

<blockquote>
<p>“<br/>
    信噪比，用于比较所需信号的程度与背景噪声的程度.  —— <a href="https://zh.wikipedia.org/wiki/%E4%BF%A1%E5%99%AA%E6%AF%94" target="_blank">信噪比</a><br/>
”  </p>
</blockquote>

<p>在这我所说的并不是信号，而是信息或知识。如果说你在网络（知乎、果壳、微博）上看完某篇（技术）文章，或者你读完某种书，留在你脑子里，你自己能信息再组织陈述出来的信息量占眼睛浏览信息量的多少呢？比例很低的原因很多很多：  </p>

<ul>
<li>信息爆炸的时代，网络上的文章大多是观点的重复累述或再陈述甚至是改变语句的抄袭，不小心选择了不正确的文章阅读自然而然没有多大益处。包括读书，现在多看书单，豆瓣书单畅销书就占据半壁江山，其实畅销书和经典书相比含金量还是大打折扣。如何选择一本“好书”，也绝非易事。如果机缘巧合，碰上了和自己相投的好书，则能影响你很长一段人生<br/></li>
<li>不懂得思考，不懂得过滤信息并再组织。成为一个有“观点”的人，需要经过很长的流程：信息获取，观察，吸收，构建自己的知识体系和世界观，最后还有一步非常非常重要却容易忽视的实践与反馈。观点需要论据支撑，最强有力的证据肯定就是实践了，在实践中思考，发现问题，才能获得最合适自己的信息<br/></li>
<li>碎片化阅读中的危害。微博上关注几个技术大V，微信上关注几个公众号，就认为自己在学习，其实自己明明是“被”学习。收藏越来越多，关注越来越多，消化越来越少。和阅读书本相比，碎片化的阅读的优势在于它的便捷，它的时间成本低，而且内容都与时俱进，但是它的劣势也相当明显，信息转化率低，很长一段时间不去组织回顾再吸收，将遗忘地很快，最终转变为信息噪音<br/></li>
<li>瞎收藏，乱收藏，信息整理不合理。碎片化的文章整理起来实属不易，比如你浏览器的Bookmarks，你微博的收藏列表，知乎的收藏，有多少你会回头去再吸收的？一个很重要的原因在于所有文章整理一锅端，仿佛一个大池子，里面很乱，自然就不愿意主动去接触了。在整理收藏文章时有时需要刻意将它们联系成一块，一个整体，让它们变得不再碎片化，仿佛一组组链表（或者说是哈希表），因为学习最怕的就是缺乏整体意识，这样不仅方便下次回归，还对自己知识图谱的构建也有很大帮助<br/></li>
</ul>

<p>其实上面分析的都是我平时不正确的行为操作，这也是我近几个月来的体会，我也深感惭愧和不安  </p>

<h4>现实和理想到底有多远？</h4>

<p>之前自己虽一直对生活和学习保持着“热度”与“激情”，其实不过是在未看清现实和看轻现实情况下的三分钟热度或五分钟热度。为何这么说？因为还是缺少实践和反馈  </p>

<p>“纸上得来终觉浅，绝知此事要躬行”。对着书本，对着Tutorial看，永远只敲一些Demo程序，就敢宣称自己懂了，已经知晓了这门技术和语言，仿佛走路都轻快了许多。现在觉得这种想法令人咋舌。一项工程的代码由40%的正常逻辑程序，还要外加60%的异常处理呢！往往这些异常处理才是最膈应你的地方，也是最能令你思维活跃，得到锻炼的下酒菜  </p>

<p>所以，学会放低姿态，安安心心做一名合格的程序狗，过五关斩六将，刻意并努力着充实自己的生活，哪怕酸甜苦辣，也绝非易事  </p>

<p>未完待续..</p>

            ]]>
        </content>
    </entry>
    
    <entry>
        <title><![CDATA[读:中位数和顺序统计量]]></title>
        <author><name>SuKai</name><uri>http://sukai.me/</uri></author>
        <link href="http://sukai.me/algorithms-order-statistic/"/>
        <updated>2016-06-30T18:00:00Z</updated>
        <published>2016-06-30T18:00:00Z</published>
        <id>http://sukai.me/algorithms-order-statistic/</id>
        <content type="html">
            <![CDATA[
             <p>今天读某公众号推送的一篇文章，题目是：求无序数组中的中位数.最简单的方法莫非就是排序，然后直接print中位数.  </p>

<p>《算法导论》第9章 中位数和顺序统计量 正好讲到了这个问题，可以在不排序的情况下求解，并且时间复杂度接近O(n)  </p>

<h4>概念</h4>

<p>找出数组中的最大值、最小值和中位数问题都可以一般化为<strong>选择问题</strong>：从一个由n个互异的元素构成的集合中选择第i个顺序统计量问题  </p>

<p>第i个顺序统计量指集合中第i小的元素，所以：  </p>

<ul>
<li>最小值是第1个顺序统计量（i=1）<br/></li>
<li>最大值是第n个顺序统计量（i=n）<br/></li>
<li>当n为奇数时，中位数的i=(n+1)/2;当n为偶数时，中位数的i=n/2和n/2+1<br/></li>
</ul>

<h4>期望为线性时间的选择算法</h4>

<p>该算法以快速排序算法为原型，采用分治法，基本思路是：任意选择一个元素作为key，基于key将数组分为两部分.左部分元素均小于等于key，右部分元素均大于key.如果key的下标idx正好等于(n+1)/2，那么key即为中位数.否则若idx&lt;(n+1)/2，那么递归去处理右部分，反之处理左部分  </p>
<div class="highlight"><pre><span class="c">#!/usr/bin/env python  </span>
<span class="c"># -*- coding: utf-8 -*-  </span>

<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">randint</span>  

<span class="k">def</span> <span class="nf">randomized_partition</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">):</span>  
    <span class="n">rand_n</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span>  

    <span class="n">key</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">rand_n</span><span class="p">]</span>  
    <span class="n">A</span><span class="p">[</span><span class="n">rand_n</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">high</span><span class="p">]</span>  
    <span class="n">A</span><span class="p">[</span><span class="n">high</span><span class="p">]</span> <span class="o">=</span> <span class="n">key</span>  

    <span class="n">i</span> <span class="o">=</span> <span class="n">low</span> <span class="o">-</span> <span class="mi">1</span>  
    <span class="n">j</span> <span class="o">=</span> <span class="n">low</span>  
    <span class="n">tmp</span> <span class="o">=</span> <span class="mi">0</span>  
    <span class="k">while</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">high</span><span class="p">:</span>  
        <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">key</span><span class="p">:</span>  
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>  
            <span class="n">tmp</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>  
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>  
            <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>  
        <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>  
    <span class="n">A</span><span class="p">[</span><span class="n">high</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>  
    <span class="n">A</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">key</span>  
    <span class="k">return</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>  

<span class="k">def</span> <span class="nf">randomized_select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>  
    <span class="k">if</span> <span class="n">low</span> <span class="o">==</span> <span class="n">high</span><span class="p">:</span>  
        <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="n">low</span><span class="p">]</span>  
    <span class="n">q</span> <span class="o">=</span> <span class="n">randomized_partition</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span>  
    <span class="n">k</span> <span class="o">=</span> <span class="n">q</span><span class="o">-</span><span class="n">low</span><span class="o">+</span><span class="mi">1</span>  
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">k</span><span class="p">:</span>  
        <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="n">q</span><span class="p">]</span>  
    <span class="k">elif</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">k</span><span class="p">:</span>  
        <span class="k">return</span> <span class="n">randomized_select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">q</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>  
    <span class="k">else</span><span class="p">:</span>  
        <span class="k">return</span> <span class="n">randomized_select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">q</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">i</span><span class="o">-</span><span class="n">k</span><span class="p">)</span>  

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>  
    <span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">]</span>  
    <span class="c"># i取4，表示求解A中的中位数  </span>
    <span class="k">print</span> <span class="n">randomized_select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>

<p>不同于快速排序会递归处理划分的两边，而randomized_select只处理换分的一边.经证明randomized_select的期望运行时间为O(n)  </p>

<h4>最坏情况为线性时间的选择算法</h4>

<p>和randomized_select一样，select算法也是通过递归划分来寻找所需元素.但是该算法能保证得到对数组的一个好的划分.根据《算法导论》中描述，select算法的步骤为：  </p>

<ul>
<li>1.将n个元素的输入数组划分为[n/5]组，每组5个元素，且至多只有一组由剩下的n mod 5个元素组成<br/></li>
<li>2.寻找[n/5]组中每一组的中位数：首先对每组元素进行插入排序，然后确定每一组的有序元素的中位数<br/></li>
<li>3.对第2步中找出的[n/5]个中位数，递归调用select以找出其中位数x（如果有偶数个中位数，为了方便，取较小那个中位数）<br/></li>
<li>4.利用修改过的partition，按中位数的中位数x对输入数组进行划分，确定x在数组中的位置k<br/></li>
<li>5.如果i==k，返回x.否则，i&lt;k，处理低区.反之在高区寻找i-k小的元素<br/></li>
</ul>
<div class="highlight"><pre><span class="c">#!/usr/bin/env python  </span>
<span class="c"># -*- coding: utf-8 -*-  </span>

<span class="k">def</span> <span class="nf">partition</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>  
    <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>  
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">):</span>  
        <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">key</span><span class="p">:</span>  
            <span class="n">idx</span> <span class="o">=</span> <span class="n">i</span>  
            <span class="k">break</span>  
    <span class="n">swap</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span>  

    <span class="n">i</span> <span class="o">=</span> <span class="n">low</span> <span class="o">-</span> <span class="mi">1</span>  
    <span class="n">j</span> <span class="o">=</span> <span class="n">low</span>  
    <span class="k">while</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">high</span><span class="p">:</span>  
        <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">key</span><span class="p">:</span>  
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>  
            <span class="n">swap</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>  
        <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>  
    <span class="n">swap</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span>  
    <span class="k">return</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>  

<span class="k">def</span> <span class="nf">insert_sort</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">):</span>  
    <span class="n">i</span> <span class="o">=</span> <span class="n">low</span> <span class="o">+</span> <span class="mi">1</span>  
    <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">high</span><span class="p">:</span>  
        <span class="n">key</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>  
        <span class="n">k</span> <span class="o">=</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span>  
        <span class="k">while</span> <span class="n">k</span> <span class="o">&gt;=</span> <span class="n">low</span> <span class="ow">and</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">key</span><span class="p">:</span>  
            <span class="n">A</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>  
            <span class="n">k</span> <span class="o">-=</span> <span class="mi">1</span>  
        <span class="n">A</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">key</span>  
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>  

<span class="k">def</span> <span class="nf">swap</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>  
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">a</span><span class="p">]</span>  
    <span class="n">A</span><span class="p">[</span><span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>  
    <span class="n">A</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>  

<span class="k">def</span> <span class="nf">select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>  
    <span class="k">if</span> <span class="n">high</span><span class="o">-</span><span class="n">low</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>  
        <span class="n">insert_sort</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span>  
        <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="n">low</span> <span class="o">+</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>  
    <span class="n">group</span> <span class="o">=</span> <span class="p">(</span><span class="n">high</span> <span class="o">-</span> <span class="n">low</span> <span class="o">+</span> <span class="mi">5</span><span class="p">)</span> <span class="o">/</span> <span class="mi">5</span>  
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">group</span><span class="p">):</span>  
        <span class="n">left</span> <span class="o">=</span> <span class="n">low</span> <span class="o">+</span> <span class="n">j</span><span class="o">*</span><span class="mi">5</span>  
        <span class="n">right</span> <span class="o">=</span> <span class="p">(</span><span class="n">low</span> <span class="o">+</span> <span class="n">j</span><span class="o">*</span><span class="mi">5</span> <span class="o">+</span> <span class="mi">4</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">low</span> <span class="o">+</span> <span class="n">j</span><span class="o">*</span><span class="mi">5</span> <span class="o">+</span> <span class="mi">4</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">high</span> <span class="k">else</span> <span class="n">high</span>  
        <span class="n">mid</span> <span class="o">=</span> <span class="p">(</span><span class="n">left</span> <span class="o">+</span> <span class="n">right</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>  
        <span class="n">insert_sort</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span>  
        <span class="n">swap</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="o">+</span><span class="n">j</span><span class="p">,</span> <span class="n">mid</span><span class="p">)</span>  
    <span class="n">key</span> <span class="o">=</span> <span class="n">select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">low</span><span class="o">+</span><span class="n">group</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">group</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>  
    <span class="n">key_idx</span> <span class="o">=</span> <span class="n">partition</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>  
    <span class="n">k</span> <span class="o">=</span> <span class="n">key_idx</span> <span class="o">-</span> <span class="n">low</span> <span class="o">+</span> <span class="mi">1</span>  
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="n">i</span><span class="p">:</span>  
        <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="n">key_idx</span><span class="p">]</span>  
    <span class="k">elif</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="n">i</span><span class="p">:</span>  
        <span class="k">return</span> <span class="n">select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">key_idx</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>  
    <span class="k">else</span><span class="p">:</span>  
        <span class="k">return</span> <span class="n">select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">key_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">i</span><span class="o">-</span><span class="n">k</span><span class="p">)</span>  

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>  
    <span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span><span class="mi">23</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">67</span><span class="p">,</span><span class="mi">45</span><span class="p">,</span><span class="mi">78</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">39</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">58</span><span class="p">]</span>  
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span>  
        <span class="k">print</span> <span class="n">select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
</pre></div>

<h4>脑洞大开：利用最小堆</h4>

<p>（依据待字闺中微信公众号推送的文章）  </p>

<p>首先，将数组的前(n+1)/2个元素建立一个最小堆.然后对于下一个元素，和堆顶元素比较，如果小于等于就丢弃之.接着看下一个元素，如果大于，则用该元素取代该顶，再调整堆.重复直至数组为空时，堆顶元素即为中位数  </p>
<div class="highlight"><pre><span class="c">#!/usr/bin/env python  </span>
<span class="c"># -*- coding: utf-8 -*-  </span>

<span class="kn">import</span> <span class="nn">heapq</span>  

<span class="k">def</span> <span class="nf">heap_select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">lens</span><span class="p">):</span>  
    <span class="n">h</span> <span class="o">=</span> <span class="p">[]</span>  
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">((</span><span class="n">lens</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">):</span>  
        <span class="n">heapq</span><span class="o">.</span><span class="n">heappush</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>  
    <span class="n">top</span> <span class="o">=</span> <span class="mi">0</span>  
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">((</span><span class="n">lens</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">lens</span><span class="p">):</span>  
        <span class="n">top</span> <span class="o">=</span> <span class="n">heapq</span><span class="o">.</span><span class="n">heappop</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>  
        <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">top</span><span class="p">:</span>  
            <span class="k">continue</span>  
        <span class="k">else</span><span class="p">:</span>  
            <span class="n">heapq</span><span class="o">.</span><span class="n">heappush</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>  
    <span class="k">return</span> <span class="n">top</span>  

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>  
    <span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>  
    <span class="k">print</span> <span class="n">heap_select</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">))</span>
</pre></div>

<hr/>

<p>参考：  </p>

<ul>
<li>《算法导论》Chapter 9<br/></li>
<li> 微信公众号：待字闺中</li>
</ul>

            ]]>
        </content>
    </entry>
    
    <entry>
        <title><![CDATA[读《你只是看起来很努力》]]></title>
        <author><name>SuKai</name><uri>http://sukai.me/</uri></author>
        <link href="http://sukai.me/you-just-seem-to-be-working-hard/"/>
        <updated>2016-06-20T15:50:00Z</updated>
        <published>2016-06-20T15:50:00Z</published>
        <id>http://sukai.me/you-just-seem-to-be-working-hard/</id>
        <content type="html">
            <![CDATA[
             <p>虽说《你只是看起来很努力》书是个纯纯粹粹的鸡汤文，不过在情绪不稳定时喝喝鸡汤也无妨  </p>

<p>PS：书名起得很假大空，明明只有Part 1部分记录了有关努力的鸡汤  </p>

<p>本文主要以摘录为主  </p>

<h4>推荐序</h4>

<p>我们之所以觉着焦虑，无非是因为现在的自己和想象中的自己，很有距离。而且我们离想象中的自己越来越远，很大程度上都是因为自己在一点点地辜负自己  </p>

<p>关于焦虑，我发现我们或多或少地都陷入了一个怪圈，这个怪圈叫：我们看似忙碌，实则焦虑。我们总是心血来潮想学习，于是买了很多单词书，再也没有翻开过；我们总是备受刺激健身，于是找了很多攻略，再也没有动过；我们总是信誓旦旦要读书，于是买了很多书，再也没有打开过  </p>

<p>我们忙碌，可我们却没有真的去了解那些自己精挑细选留下的内容。我们花时间收集，却忘了最重要的其实是花时间消化  </p>

<p>那么怎么打败焦虑？最好的办法就是去做那些让你焦虑的事情  </p>

<p>逐渐，我开始每天给自己写计划，每个月给自己设定目标，不为别人不为表象地努力。路一步步地走，走得很慢，但没有停  </p>

<h4>Part 1：梦想和奋斗—你只是看起来很努力</h4>

<p><strong>你以为你在合群，其实你在浪费青春</strong>  </p>

<p>合到该合的群，寻觅自己要的，无论是理想，还是朋友，才是大学四年该做的。我一直坚信，英雄，永远是孤独的，只有小喽啰才扎堆。无论如何，那些有点成就的人，都不合群  </p>

<p><strong>以赚钱为目的的兼职，是最愚蠢的投资</strong>  </p>

<p>那些有工作、有钱人的生活，不要羡慕，因为随着你年龄的增长，迟早会有。但是，你有而他们没有的东西：时间、青春。其实格外重要  </p>

<p><strong>最好的休息</strong>  </p>

<p>休息的方式不是疯狂地睡大觉，而是换个脑子去做其他的事情  </p>

<p>很多时候，我们觉着累，打不起精神去做一些事情；我们觉着很困，却在床上睡不着。其实，不是因为我们老了，而是因为我们没有合理运用时间。我们的时间如此宝贵，为什么不去规划地使用，很多所谓的休息时间，根本不是去蒙头大睡，而是去调整生活状态，换个大脑。睡觉只是众多放松方式中的一种，除此之外，我们还有很多方法  </p>

<p><strong>优秀不够，你是否无可替代</strong>  </p>

<p>毕竟努力的人很多，在大城市，最不缺的就是梦想，最不差的就是优秀的人  </p>

<p>年轻人，在学习的路上，不要低着头看书，多去人才市场看看现在的社会需要什么专长，上网看看大型公司缺的施恩么人，把一技之长磨得无可替代，变成自己喜欢的事业  </p>

<p><strong>这世上一定有人，过着你想要的生活</strong>  </p>

<p><strong>没有一条路是白走的</strong>  </p>

<p>有时候只有走错了路，才逐渐明白自己要的未来；只有交错了朋友，才逐渐知道什么是患难见真情；只有爱错过人，才逐渐懂得真爱是什么  </p>

<p><strong>别和负能量的人在一起</strong>  </p>

<p><strong>为什么很多人的新年梦想只是梦想</strong>  </p>

<p>我在上课的时候，特别喜欢培养学生写日记的习惯。我告诉所有的学生，如果你不愿意写，也要在夜晚睡觉前闭目养神地静静思考一下今天做了什么，明天还要做什么。思考的时候要分成必须做的、喜欢做的和可做可不做的  </p>

<p><strong>最好的省钱方法是赚钱</strong>  </p>

<p>虽然钱不是万能的，但是没有钱你会发现寸步难行。那之后，我学会了不跟别人斗争，很多时候网上有人对我发起了攻击，我唯一能做的，就是回避。因为这些斗争没有意义，而有这些时间，还不如多多提升自己或者多去赚点钱  </p>

<p>中国有一句古话，思路决定出路，屁股决定脑袋。一个脑袋里面整天只有几角钱的人，相比这辈子不会赚什么大钱；一个只会知道如何省钱的人，也自然而然地失去了如何赚钱的思维。我不是让大家去浪费，可你是否想过，一些过于节省的生活，就是浪费：你每天都在争论那几角钱，浪费了精力和时间去读书学习；把隔夜的剩菜热了吃，吃坏肚子去医院花更多钱。真正省钱的方式，是去赚钱，是让自己变得更强大，而不是为了几角钱花自己最宝贵的时间去永无休止地争论  </p>

<p><strong>你总要度过生存期，才能谈生活和梦想</strong>  </p>

<p>无论在哪里，你都先要解决生存的问题，然后谈生活和梦想。我想，任何梦想和生活，都是基于度过生存期那段连下个馆子都计划再三的时光后的，否则，都是空中楼阁。在度过生存期的过程中，可能会失去一些宝贵的东西，或过得不如意。但不忘初心，记得每天提醒自己：这些黑暗只是为了今后的黎明，做这些不愿意的事情只是为了以后能更好地站起来。这样便好</p>

            ]]>
        </content>
    </entry>
    
    <entry>
        <title><![CDATA[2016上半年书单]]></title>
        <author><name>SuKai</name><uri>http://sukai.me/</uri></author>
        <link href="http://sukai.me/2016-first-half-booklists/"/>
        <updated>2016-06-19T16:30:00Z</updated>
        <published>2016-06-19T16:30:00Z</published>
        <id>http://sukai.me/2016-first-half-booklists/</id>
        <content type="html">
            <![CDATA[
             <p>大概是3月份入手了Kindle PaperWhite 3，发现真的很喜欢这个电子阅读器。所以平时的阅读习惯就变成了从readcolor.com和readfree.me下载许多mobi书籍存在Kindle上。有时候下载些epub的在果6的多看阅读上浏览  </p>

<p>我上半年似乎看了不少小说（：逃，下面就粗略地从自己的评分由高往低简单记录下  </p>

<ul>
<li><strong>《孤独小说家》</strong>：书名虽然叫作“孤独小说家”，讲的是一位小说家青田耕平坚持写作十年，才收获梦想拿到直本奖。但给我留下最深刻印象的是耕平丧妻后仍不浮躁、坚守内心纯真孤独的那份难得可贵<br/></li>
<li><strong>《岛上书店》</strong>：本以为玛雅的出现拯救了A.J.，没想到结局还是不尽人意，这就是生活<br/></li>
<li><strong>《时间简史：从大爆炸到黑洞》</strong>：这是本只有全球5%的人才能看懂的书，可惜我不是那5%。但这又是一本让你有些熟悉的书，里面有部分结论在高中物理，大学物理都有所涉及，里面还有部分结论和猜想被众多科幻片引入。有机会会翻阅第二遍<br/></li>
<li><strong>《统计学习方法》</strong>：机器学习入门经典书籍<br/></li>
<li><strong>《机器学习实战》</strong>：理论看多了，来点代码非常不错<br/></li>
<li><strong>《高效能程序员的修炼》</strong>：教你如何做一名敏捷式程序员，和《高效程序员的45个习惯》有重合观点<br/></li>
<li><strong>《把时间当作朋友》</strong>：非常好的一本书，不多说<br/></li>
<li><strong>《奇特的一生》</strong>：李笑来推荐的书。柳比歇夫一直在算自己每天的24小时都花在了什么地方，相当自律的一个人，警告自己珍惜时间<br/></li>
<li><strong>《富爸爸穷爸爸》</strong>：坚定了自己未来要给自己打工的决心<br/></li>
<li><strong>《深入浅出统计学》</strong>：回顾“统计学”的一本好书<br/></li>
<li><strong>《拉伸：最好的运动》</strong>：作为一名程序员，拉伸很有必要。书里附送了一张拉伸教程表，可以学习下<br/></li>
<li><strong>《Python科学计算》</strong>：不错的一本工具书。教你如何利用Python进行科研<br/></li>
<li><strong>《重来：更为简单有效的商业思维》</strong>：有关创业的<br/></li>
<li><strong>《从0到1：开启商业与未来的秘密》</strong>：另一本有关创业的<br/></li>
<li><strong>《你只是看起来很努力》</strong>：李尚龙杂文合集。鸡汤型书籍，但却很有启发性，推荐阅读<br/></li>
<li><strong>《一地鸡毛》</strong>：令人绝望的现实<br/></li>
<li><strong>《你今天真好看》</strong>：很好看的漫画，很萌<br/></li>
<li><strong>《父与子全集》</strong>：又一本萌萌哒的漫画，父与子之间的故事<br/></li>
<li><strong>《赤裸裸的统计学》</strong>：结合实际案例讲述的入门级统计学科普书，不推荐你逐字逐句去细读<br/></li>
<li><strong>《台湾这些年所知道的祖国》</strong><br/></li>
<li><strong>《不要等到毕业以后》</strong>：里面相当多的观点深有体会<br/></li>
<li><strong>《你所谓的稳定，不过是在浪费生命》</strong><br/></li>
<li><strong>《别告诉我你会记笔记》</strong>：有些关于做笔记的建议还是值得采纳的。特别是将脑袋中瞬息的灵感记在本子上，并写写画画，思绪更容易被激发<br/></li>
<li><strong>《4点起床》</strong>：这本书最大的收获就是提醒你珍惜时间，尤其是早晨上半午的时间<br/></li>
<li><strong>《考拉小巫的英语学习笔记》</strong>：作者的执行力很强，令人佩服。自己是自愧不如了<br/></li>
<li><strong>《Automate the Boring Stuff with Python》</strong>：教你如何利用Python帮你处理一些繁琐的事<br/></li>
<li><strong>《少有人走得路》</strong>：偏心理学的书。书中讲：大部分人不愿意正视“人生苦难重重”，总会选择先享受，然后逃避问题和痛苦，这句说得太好了。所以每个工作日的早晨都应该推迟满足感，首先在工作的第一个钟头去解决那些最麻烦的事情，即先吃苦再享受<br/></li>
<li><strong>《天才在左，疯子在右》</strong>：若不是书名的提醒，你不会发现这本书是记录精神病患者的。那些精神病患者的想象力、智力似乎都比正常人惊人的高，令人吃惊<br/></li>
<li><strong>《Introducing Github》</strong>：介绍Github的一本书<br/></li>
<li><strong>《Think Python》</strong><br/></li>
<li><strong>《绿皮火车》</strong>：为什么读起来很费力，不轻松<br/></li>
<li><strong>《哪来的天才？》</strong>：keep practiceing<br/></li>
<li><strong>《创业时，我们在知乎聊什么？》</strong>：如果自己真的创业了，回来会仔细品读的<br/></li>
<li><strong>《深入浅出数据分析》</strong>：个人觉着不如《深入浅出统计学》<br/></li>
<li><strong>《重新定义公司》</strong>：Google发展史，里面有一章讲google为什么退出中国市场的<br/></li>
<li><strong>《创京东</strong>》：京东发展史，没有细看。很佩服刘强东，事业有成，还有奶茶妹妹，人生赢家<br/></li>
<li><strong>《敏感的人：如何面对外界的压力》</strong><br/></li>
<li><strong>《轻松学会独立思考》</strong><br/></li>
<li><strong>《我们台湾这些年》</strong>：流水账文章，比不上《台湾这些年所知道的祖国》<br/></li>
<li><strong>《大数据时代》</strong>：泛泛而谈的一本书<br/></li>
<li><strong>《大教堂与集市》</strong>：看得翻译本，不是很能懂<br/></li>
<li><strong>《中国人，你为什么不快乐》</strong><br/></li>
<li><strong>《沉默的大多数》</strong><br/></li>
<li><strong>《那些男孩教我的事》</strong><br/></li>
<li><strong>《黑客：计算机革命的英雄》</strong><br/></li>
<li><strong>《我这个普通人的生活》</strong><br/></li>
<li><strong>《十四岁》</strong>：日本人14岁的时候就开始找女生援交了？<br/></li>
<li><strong>《互联网+：从IT到DT》</strong><br/></li>
<li><strong>《年轻时做过的那些荒唐事儿》</strong><br/></li>
<li><strong>《生命中最简单又困难的事》</strong><br/></li>
<li><strong>《当你生病时，你会想起谁？》</strong><br/></li>
</ul>

<p>总共51本，下半年继续坚持</p>

            ]]>
        </content>
    </entry>
    
</feed>