<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>苏苏</title>
    <link href="" rel="self" />
    <link href="http://sukai.me/" />
    <updated>2015-11-29T22:00:00Z</updated>
    <id>http://sukai.me/</id>
    
    <entry>
        <title><![CDATA[微信公众号数据监测项目]]></title>
        <author><name>SuKai</name><uri>http://sukai.me/</uri></author>
        <link href="http://sukai.me/wx-gsdata/"/>
        <updated>2015-11-29T22:00:00Z</updated>
        <published>2015-11-29T22:00:00Z</published>
        <id>http://sukai.me/wx-gsdata/</id>
        <content type="html">
            <![CDATA[
             <p>最近在给本科实验室的微信监测项目写后台数据源抓取程序，业务逻辑非常简单，在开始编码之前，我设计了一个自认为比较合理（可扩展的）分层。由于数据源是用的一家公司的restful api，使用期间，遇到并解决了很多问题（包括，找出了那家第三方数据公司后台程序和api文档的诸多bug），在这篇博客中记录一下  </p>

<h3>后台设计与编码</h3>

<p>先在这里阐述一下我们项目的数据需求。我们需要监测苏州地区微信公众号的如下信息：  </p>

<ul>
<li>微信公众号的information：公众号描述，联系人名称，公众号所属城市等有关公众号的信息<br/></li>
<li>微信公众号的daily数据：每天的总文章数，总阅读数，总点赞数<br/></li>
<li>每篇文章的daily数据：每天阅读数，点赞数<br/></li>
<li>微信公众号的week数据：一周中的总文章数，总阅读数，总点赞数<br/></li>
<li>每篇文章的week数据：该文章一周的阅读数，点赞数<br/></li>
</ul>

<p>要求就是，从某个api获取这些数据，做持久化入库操作；之后，我们会做一个前台界面（表格展示，图表展示，包括折线图，柱状图等等）方便非技术人员进行监测。前台有关html，js这块不是我编码，我负责数据的来源，下面来看一下我的数据抓取后台分层：  </p>

<p>project package目录：  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/wsa.png" width = "200" height = "500" align=center />  </p>

<p>流程图：  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/wsa_project.png" width = "790" height = "300" align=center />  </p>

<p>流程图看不清，点击查看大图吧（右击查看图像）&hellip;  </p>

<p>业务逻辑已经被分析彻底了，开始编码吧：  </p>

<p>刷刷刷！！！很快就编码完成（个人觉得，都是体力活，累&hellip;）  </p>

<p>测试：先抓取了5个公众号，10月份31天的数据。没问题，是对的！  </p>

<h3>找到对方api系统bug</h3>

<p>我所写的后台抓取程序，没有涉及到多线程（当时暑假在同程旅游实习，爬大众点评的商品数据，在线程池中运行，一个星期爬了将近百万数据量）。现在的后台程序，就是单条线程不停地运行，请求，存库&hellip;一直循环  </p>

<p>问题来了，对方api系统的bug找出来。具体bug就不说了，最后我汇总了他们的bug和文档bug，和工作人员沟通，他们也很快修复了，这是他们后来回复我的邮件：  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/gsdata_bug_reply.png" width = "730" height = "250" align=center />  </p>

<p>ok，截至目前，10个公众号，1月1号～11月23号的数据全部拿出来了，数据库daily表里面有10327条数据  </p>

<h3>数据清理工作：自动化脚本的威力！</h3>

<p>ok，本以为项目可以告一段落了。得知，制作前台界面的小伙伴，调用我后台数据过程中，发现了数据错误现象  </p>

<p>有些棘手了，确实有错误的数据存放在数据库中，但是1w多条，我该怎么排查？  </p>

<p>自动化脚本的威力！！  </p>

<p>我想，编码最大的快乐就是能帮助我们解决琐碎的事，能帮助我们批量解决问题  </p>

<p>刷刷刷！我对10个公众号，1.1 ~ 11.23进行排列组合，循环遍历检查，一共遍历10*11*30（10个公众号，11个月，每个月约30天）  </p>

<p>自动话脚本OK了，运行了8，9mins，结果出来了：  </p>

<p>一共1865条数据有不符合预期的情况，一共分为三种情况：  </p>

<ul>
<li>数据不一致现象：公众号某天的总阅读数，总点赞数，和该公众号该天所有文章的阅读数，点赞数之和不相等<br/></li>
<li>数据库中，部分公众号没有某一天的公众号daily数据<br/></li>
<li>数据库中，部分公众号没有某一天的文章daily数据<br/></li>
</ul>

<p>不符合预期的结果全部被我揪出来了，我该拿它们怎么办？  </p>

<p>自动化脚本的威力：修理他们！！！  </p>

<p>刷刷刷，OK了！  </p>

<p>我们来看一下结果：  </p>

<p>总共1865条不符合预期的数据，经检查：  </p>

<ul>
<li>api bug：api给我的数据就不一致，总共420条<br/></li>
<li>经修理符合要求的数据：39条<br/></li>
<li>公众号确实没有daily数据的，也就是该该公众号当天确实没有推送任何文章：1406条<br/></li>
</ul>

<p>由此可知：我些的后台程序的错误率为：39/1865，或者是39/10327，比较低  </p>

<p>关于那420条api bug返回的数据，算是我发现的另一处bug，我还未和对方沟通  </p>

<p>PS：关于数据清理的工作，我在这篇博客中介绍的比较简单，编写自动化脚本我也一笔带过；但，实则却要理清楚数据清理的逻辑，即：  </p>

<ul>
<li>数据不符合要求的条件是什么？<br/></li>
<li>出现了三种不符合要求的情况，针对这三种，我该怎么修正他们？<br/></li>
<li>如何记录这些错误数据？<br/></li>
</ul>

<p>理不清这些逻辑，呵呵，就更别提写什么脚本帮你处理了。理清之后，脚本刷刷地运行，节省了很多时间  </p>

<p>脚本分别用了python和java语言，期间遇到一些问题，在这里记录一下：  </p>

<ul>
<li><a href="http://stackoverflow.com/questions/4559699/python-mysqldb-and-library-not-loaded-libmysqlclient-16-dylib">python-mysqldb-and-library-not-loaded-libmysqlclient-16-dylib</a><br/></li>
<li><a href="http://blog.csdn.net/dkman803/article/details/1925326">Python MySQLdb 使用utf-8 编码插入中文数据</a><br/></li>
<li><a href="http://zetcode.com/db/mysqlpython/">使用python操作mysql</a><br/></li>
</ul>

<h3>总结</h3>

<h4>第一点：搜索引擎的使用</h4>

<p>强烈建议放弃baidu，拥抱google  </p>

<p>强烈建议放弃baidu，拥抱google  </p>

<p>强烈建议放弃baidu，拥抱google  </p>

<p>重要的事情说三遍！！原因很简单：开发中遇到问题，baidu出来的答案，前几条都是百度知道；google出来的前几条都是stackoverflow。这就是差距  </p>

<h4>第二点：人要学会变得懒惰</h4>

<p>所有程序能帮你完成的事情，我们人为什么还要去做，这简直就是浪费精力  </p>

<p>学好脚本语言，拥有强大的脑洞，生活效率会大大提高  </p>

<h4>第三点：和靠谱的人合作</h4>

<p>找到这家数据公司的诸多文档问题后，我很想吐槽这家数据公司，文档不认真写，感觉有点坑用户  </p>

<p>抛除这些第三方系统的错误或者bug，我想我的工作量很减少很多，我会腾出更多时间去学习其余的知识  </p>

<p>就先写这么多吧，滚去睡觉了！</p>

            ]]>
        </content>
    </entry>
    
    <entry>
        <title><![CDATA[Machine Learning公开课总结（一）]]></title>
        <author><name>SuKai</name><uri>http://sukai.me/</uri></author>
        <link href="http://sukai.me/ml-cousera-one/"/>
        <updated>2015-11-25T20:00:00Z</updated>
        <published>2015-11-25T20:00:00Z</published>
        <id>http://sukai.me/ml-cousera-one/</id>
        <content type="html">
            <![CDATA[
             <h3>一. 前言</h3>

<p>花了一个多月的时间（中间有段时间在为本科实验室项目写后台程序）在cousera上学习Andrew Ng的机器学习入门公开课，11周的课程马上就要结束了。整体上，我觉得这11周的课程相对比较简单，很容易听懂，少去很多数学的原理推导，很适合初学者，也让初学者建立了机器学习领域的一些宏观概念。之前，很多人推荐李航博士的《统计学习方法》作为入门教程，我个人认为，看完Andrew Ng的课程视频后，再去阅读《统计学习方法》，会轻松很多  </p>

<p>下面我将连载几篇文章，总结这11周课程中的一些内容。主要根据我看视频时，笔记本上纪录的内容为主  </p>

<p>好了，废话不多说。我先总结Week 1~3，主要涉及到监督学习中的线性回归和逻辑回归，避免过拟合等内容  </p>

<h3>二. Week One</h3>

<h4>2.1 Introduction</h4>

<h5>2.1.1 环境的建立</h5>

<p>教你搭建Octave/MATLAB，这部分不多说  </p>

<h5>2.1.2 Introduction</h5>

<p>说明什么是监督学习，什么是非监督学习  </p>

<p>监督学习：  </p>

<ul>
<li>对于离散变量，主要是分类问题<br/></li>
<li>对于连续变量，主要是回归问题<br/></li>
</ul>

<p>非监督学习：数据集没有明确的标签，我们需要在这堆数据中寻找他们的数据结构，常见的：聚类问题  </p>

<h4>2.2 Linear Regression with One Variable</h4>

<p>一元线性回归问题  </p>

<h5>2.2.1 描述一个简单机器学习模型</h5>

<p>首先，说明在一个机器学习模型中，要用到的几个字母变量（符号）的定义：  </p>

<ul>
<li>E: Experience<br/></li>
<li>T: Tasks<br/></li>
<li>P: Performance<br/></li>
<li>x: 特征变量<br/></li>
<li>y: 目标变量<br/></li>
<li>m: 训练集的数目<br/></li>
<li>(x, y): 训练样本<br/></li>
<li>(x(i), y(i)): 第i个训练样本<br/></li>
<li>h: 预测函数<br/></li>
</ul>

<p>好了，有了这些符号，我们就可以表示一个机器学习模型了：  </p>

<p>首先，既然是线程回归问题，我们就先假设预测函数h的公式为：<img src="http://7xl2fd.com1.z0.glb.clouddn.com/预测函数.png" width = "140" height = "25" align=center />  </p>

<p>其中，<img src="http://7xl2fd.com1.z0.glb.clouddn.com/模型参数.png" width = "80" height = "25" align=center />，我们称为模型参数  </p>

<p>然后，学习算法（learning algorithm）会通过training set训练集，得到一个最优的预测函数h（对应一个模型参数）。之后，从测试集中取出x，通过预测函数的映射，即可得到预测的目标变量y  </p>

<p>需要说明的是：如何得到一个最优的预测函数h？  </p>

<p>很简答，就是通过代价函数，寻找使得代价函数最小的模型参数θ  </p>

<p>平方误差是解决回归问题的常用方法，定义一个代价函数J就很简单：  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/cost-function.png" width = "300" height = "45" align=center />  </p>

<p>通过某种方法，寻找到使得代价函数最小的那个模型参数θ，即是我们最终需要的结果  </p>

<h5>2.2.2 如何求解模型参数θ（专业地说：如何进行参数学习）</h5>

<p>cousera上介绍了一种最经典的算法：<strong>梯度下降算法</strong>  </p>

<p>大致的工作过程即，从某个随机的θ0, θ1开始，不停地改变θ0, θ1的值，以保证J(θ0, θ1)不断地减小，直至在某个最小值处结束（不停地在迭代运行）  </p>

<p>来张图理解一下（仿佛一个人下山的过程）  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/gradient%20descent%20img.png" width = "700" height = "360" align=center />  </p>

<p><strong>梯度下降算法定义：</strong>  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/gradient%20descent%20define.png" width = "400" height = "100" align=center />  </p>

<p>其中，α叫做学习速率（learning rate），α很大，下山的步伐会迈的很大；α很小，下山的步伐会迈的相对较小。α用以控制我们以多大的幅度去更新参数θj  </p>

<p>α不宜设置过大，否则容易出现波动，难以收敛  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/梯度下降算法中的学习速率.png" width = "700" height = "360" align=center />  </p>

<p>再看看α后面的偏导数项，它代表什么意思呢？  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/梯度下降算法中的偏导数.png" width = "700" height = "380" align=center />  </p>

<p>先看上面的图，偏导数表示红色线的斜率，此时斜率为正，那么θ1就会减去α*一个正数，θ1会逐渐变小，直至最低点  </p>

<p>下面的图，斜率为负，θ1会逐渐变大，直至最低点  </p>

<p>ok，梯度下降算法定义解释完毕。在本例中，hθ(x)=θ0+θ1*x，那么梯度下降算法的具体步骤为：  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/一元线性回归的梯度下降算法.png" width = "430" height = "180" align=center />  </p>

<p>此时，已经具体到了θ0和θ1的具体变换过程  </p>

<p>需要注意的是：θ0和θ1是需要同时更新变化执行迭代的  </p>

<h3>三. Week Two</h3>

<h4>3.1 Linear Regression with Multiple Variables</h4>

<p>多元线性回归问题  </p>

<p>既然已经不止一个特征变量了，那么之前用x表示特征变量，现在要换一种表示方法了：  </p>

<ul>
<li>n: 表示特征值的个数<br/></li>
<li>xj(i)：第i个训练样本的第j个特征的值<br/></li>
</ul>

<p>此时预测函数h表示为：hθ(x) = θT*x  </p>

<p>为了符号的方便表示，我们总是定义x(j)0为1  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/多元线性回归的预测函数.png" width = "550" height = "280" align=center />  </p>

<p>下面，解释在多元线性回归中的梯度下降算法：  </p>

<p>首先，是它的代价函数  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/多元线性回归的代价函数.png" width = "520" height = "110" align=center />  </p>

<p>然后是θj的变换过程  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/多元线性回归的梯度下降算法.png" width = "450" height = "280" align=center />  </p>

<p>ok，下面再介绍梯度下降算法在实际应用中的两个注意点：  </p>

<ul>
<li>特征缩放<br/></li>
<li>学习速率的选择<br/></li>
</ul>

<p><strong>特征缩放：</strong>  </p>

<p>假设，现有一个房价预测系统，若现有两个特征：x1, x2。x1表示房屋的面积，取值范围：0~2000，x2表示房间的个数，取值范围：1~5  </p>

<p>这两个特征的取值的取值规模不在一个级别，使用梯度下降算法时，收敛不快，且容易发生波动。应使用特征缩放方法将两个特征的取值范围约束到大体一致的范围：  </p>

<ul>
<li>一种方法是：x1=x1/2000，每个特征处以该特征值的最大值。这样，取值范围都被缩小为0~1。一般-1~1, -1/3~1/3和-3~3均可接受<br/></li>
<li>第二种方法，归一化处理：（xi-平均值）/（MAX-MIN）<br/></li>
</ul>

<p><strong>学习速率α</strong>  </p>

<p>上面已经解释了learning rate的意义。正常的梯度下降算法，随着迭代次数的增加，代价函数逐渐减小；不正常的工作流程，有可能出现波动现象  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/梯度下降算法的迭代过程.png" width = "440" height = "300" align=center />  </p>

<p>不正常的工作现象：  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/不正常的梯度下降过程.png" width = "510" height = "300" align=center />  </p>

<p>看了公开课后的结论是：α一般从0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1开始选择  </p>

<p>截至目前，我们一直都在使用梯度下降算法求解最优的模型参数。梯度下降算法最显著的特征就是，需要不停地迭代  </p>

<p>视频中还介绍了另一种求解方法：<strong>正规方程（Normal Equation）</strong>  </p>

<p>θ=(xT*x)-1*xT*y（证明略&hellip;）  </p>

<p>它一步即可得到最优的模型参数值  </p>

<p>现在，我们来比较一下：  </p>

<table border="1">  
<tr>  
<th>梯度下降算法（Gradient Descent）</th>  
<th>正规方程（Normal Equation）</th>  
</tr>  
<tr>  
<td>需要选择学习速率α</td>  
<td>不需要选择学习速率α</td>  
</tr>  
<tr>  
<td>需要多次迭代</td>  
<td>不需要迭代，一步得结果</td>  
</tr>  
<tr>  
<td>当特征数目n特别大时，也可以正常工作</td>  
<td>当特征数目n特别大时，矩阵纬度很大，计算非常慢（n=100,1000还好，n为千万时，计算非常慢）</td>  
</tr>  
</table>  
  

<h3>四. Week Three 逻辑回归</h3>

<h4>4.1 分类问题</h4>

<p>先从两元分类问题进行研究：  </p>

<p>y∈{0, 1}，定义y=0时，属于Negtive Class；y＝1时，属于Positive Class  </p>

<p>那么，怎样让预测函数 0 &lt;= hθ(x) &lt;= 1？  </p>

<p>这里介绍S型函数g(z)=1/(1 + e-z)  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/S型函数.png" width = "510" height = "300" align=center />  </p>

<p>S型函数的取值范围在(0, 1)，则hθ(x) = 1/（1 + e-(θT*x)）；而且hθ(x) = P(y=1 | x;θ) = 1 - P(y=0 | x;θ)  </p>

<ul>
<li>当θT*x &gt;= 0，hθ(x) &gt;= 0.5，y为1<br/></li>
<li>当θT*x &lt; 0，hθ(x) &lt; 0.5，y为0<br/></li>
</ul>

<p>举例：hθ(x) = -3 + x1 + x2；当-3 + x1 + x2 &gt;= 0，预测y=1；此时决策边界为 x1 + x2 = 3  </p>

<p>需要注意的是：我们不是用训练集来定义决策边界的，而是用来拟合参数θ的，θ决定了决策边界  </p>

<h4>4.2 代价函数和梯度下降算法</h4>

<p>之前在线性回归中定义的平方误差代价函数，是否能用到逻辑回归中呢？  </p>

<p>答案是：不能  </p>

<p>因为逻辑回归中的预测函数hθ(x)是非线性函数，得到的代价函数将是非凸函数，可能是这样：  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/非凸代价函数.png" width = "410" height = "250" align=center />  </p>

<p>它有许多局部最优值，梯度下降算法不能保证收敛到全局最优值。所以，我们希望代价函数是有类似于“单弓形”函数，能确保找到全局最小值  </p>

<p>我们需要重新定义逻辑回归的代价函数了  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/逻辑回归的代价函数.png" width = "490" height = "150" align=center />  </p>

<p>当 y = 1，hθ(x) -&gt; 0, cost -&gt; ∞  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/y=1的逻辑回归代价函数.png" width = "410" height = "250" align=center />  </p>

<p>当 y = 0，hθ(x) -&gt; 1, cost -&gt; ∞  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/y=0的逻辑回归代价函数.png" width = "410" height = "250" align=center />  </p>

<p>ok，新定义的代价函数，符合我们的要求  </p>

<p>此时的代价函数公式，用一行表示为：  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/逻辑回归代价函数总式子.png" width = "630" height = "200" align=center />  </p>

<p>使用梯度下降算法，迭代并同时更新θ0～θn  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/逻辑回归梯度下降算法.png" width = "530" height = "200" align=center />  </p>

<p>和线性回归的一样，只不过hθ(x)的表达式不同  </p>

<p>当然，特征缩放也是适用于逻辑回归的  </p>

<h4>4.3 高级算法</h4>

<p>除了梯度下降，正规方程，还有许多可以计算出最优模型参数θ的算法  </p>

<p>视频中还提到了：BFGS, L-BFGS和Conjugate gradient  </p>

<p>这些高级算法比梯度下降要快，无需选择学习速率，但是更复杂。具体编程时，可以考虑使用现成的类库，帮助我们快速解决问题  </p>

<h4>4.4 多元分类问题</h4>

<p>三元分类问题  </p>

<p>可以转换为三个两元分类问题来做  </p>

<p>hθ(i)(x) = P(y = i | x:θ)，其中 i＝1，2，3  </p>

<p>训练的出θ后，预测时，选择hθ(i)(x)最大的那个i，就是目标变量的分类  </p>

<h4>4.5 过拟合问题</h4>

<h5>4.5.1 什么是过拟合？什么是欠拟合？</h5>

<ul>
<li>欠拟合：预测模型没有能很好的拟合训练数据，拟合效果差。产生高偏差<br/></li>
<li>过拟合：能很好地拟合训练数据。但预测函数变量过多，而没有足够多的数据去约束变量的个数（预测测试集，效果会非常差，即泛化效果差）。产生高方差<br/></li>
</ul>

<p><a href="http://www.zhihu.com/question/20448464">高偏差；高仿差..click for infos</a>  </p>

<p>＊泛化：一个测试模型应用到新样本的能力  </p>

<p>这里，先不讲如何识别过拟合问题，后面的课程讲解了如果利用工具去识别过拟合问题（后续整理）  </p>

<p>往往，我们往预测模型中，增加了太多太多的特征，容易导致过拟合问题  </p>

<p>如何避免过拟合问题：  </p>

<ul>
<li>减少特征变量数目（缺点：同时也会丢失一些重要信息）<br/></li>
<li>正则化（进行某种惩罚措施）：保留所有的特征变量，但是降低模型参数θj的数量级或者值<br/></li>
</ul>

<p>正则化技术非常有效，由于是在我们预测模型中有许多特征变量，每个特征变量都能帮助我们预测目标变量，这样我们就可以不用舍弃任何一个特征变量了  </p>

<h5>4.5.2 线性回归代价函数中使用正则化技术：</h5>

<p>重写线性回归中的代价函数：  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/正则化的线性回归代价函数.png" width = "530" height = "150" align=center />  </p>

<p>λ为正则化参数。λ越大，惩罚程度越大，模型参数θj会越小，有可能会导致欠拟合问题  </p>

<h5>4.5.3 线性回归梯度下降算法中使用正则化技术：</h5>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/正则化的梯度下降算法.png" width = "650" height = "400" align=center />  </p>

<p>注意θ0是单独的一种  </p>

<h5>4.5.4 正规方程中使用正则化技术：</h5>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/正则化的正规方程.png" width = "380" height = "180" align=center />  </p>

<h5>4.5.5 逻辑回归代价函数中使用正则化技术：</h5>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/逻辑回归正则化代价函数.png" width = "730" height = "300" align=center />  </p>

<h5>4.5.6 逻辑回归梯度下降算法中使用正则化技术：</h5>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/逻辑回归正则化梯度下降算法.png" width = "730" height = "350" align=center />  </p>

<p>这个和线性回归中的一样，hθ(x)不同而已  </p>

<h5>4.5.6 高级算法中使用正则化技术：</h5>

<p>略  </p>

<h3>五. 结语</h3>

<p>ok，前三章整理完了。过几天整理神经网络那块  </p>

<p>感谢七牛云存储为文章提供图片CDN支持  </p>

<p>文章若有错误，请指正</p>

            ]]>
        </content>
    </entry>
    
    <entry>
        <title><![CDATA[自顶向下学习Tornado源码(一)]]></title>
        <author><name>SuKai</name><uri>http://sukai.me/</uri></author>
        <link href="http://sukai.me/tornado-source-code-one/"/>
        <updated>2015-11-21T10:00:00Z</updated>
        <published>2015-11-21T10:00:00Z</published>
        <id>http://sukai.me/tornado-source-code-one/</id>
        <content type="html">
            <![CDATA[
             <h3>一. 从Hello Tornado开始</h3>

<h4>1.1 Hello World</h4>

<p>用tornado写的一个最简单的demo，但已经用到了很多tornado的核心类：httpserver, ioloop, Application&hellip;  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/hello-tornado.png" width = "500" height = "400" alt="tornado-demo" align=center />  </p>

<h4>1.2 调试运行</h4>

<p>利用pdb进行调试，打印方法栈信息，在IndexHandler中加入代码：  </p>
<div class="highlight"><pre><span class="n">greeting</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_argument</span><span class="p">(</span><span class="s">&#39;greeting&#39;</span><span class="p">,</span> <span class="s">&#39;Hello&#39;</span><span class="p">)</span>  
<span class="kn">import</span> <span class="nn">pdb</span>  
<span class="n">pdb</span><span class="o">.</span><span class="n">set_trace</span><span class="p">()</span>   
<span class="bp">self</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">greeting</span> <span class="o">+</span> <span class="s">&#39;, friendly user!&#39;</span><span class="p">)</span>
</pre></div>

<p>利用curl或者浏览器，触发程序，查看栈桢  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/stack-hello-tornado.png" width = "500" height = "400" alt="stack-tornado-demo" align=center />  </p>

<h4>1.3 猜测</h4>

<p>图中模模糊糊给了我们一些执行流程信息，我又参考了几篇文章，先得出一些结论  </p>

<ul>
<li>ioloop：核心的io循环，用于处理所有socket的read, write, accept等事件。其i/o模型视主机而定，一般Linux平台采用epoll(关于i/o模型，<a href="http://sukai.me/linux-five-io-models/">Click For More..</a>)<br/></li>
<li>iostream：封装了对socket的异步读写操作<br/></li>
<li>httpConnection(代码在httpserver.py中)：接受HTTP请求，根据路由信息，调用相应的Handler。再把相应的数据写会client<br/></li>
</ul>

<p>tornado服务器的大体流程如下图(图片来源：<a href="http://kenby.iteye.com/blog/1159621">kenby.iteye</a>)  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/tornado-core.png" width = "500" height = "400" alt="tornado-core" align=center />  </p>

<p>首先，服务器创建监听套接字，同时将自己注册进ioloop进行事件循环检查（主要检查是否有新的客户端连接到来）。client到达后，服务器通过accept函数，返回一个client socket，同时client socket被注册进ioloop进行事件循环检查（检查read，write等事件）。客户端若向服务器发起读操作，HTTPConnetcion通过_on_headers解析HTTP头，之后通过iostream的write操作，将数据写给客户端  </p>

<h3>二. HTTPServer</h3>

<p>按照自顶向下的顺序，先阅读HTTPServer的源码  </p>

<p>HTTPServer继承自TCPServer  </p>

<p>刚刚的demo中，与HTTPServer相关的只有两条编程语句  </p>
<div class="highlight"><pre><span class="n">http_server</span> <span class="o">=</span> <span class="n">tornado</span><span class="o">.</span><span class="n">httpserver</span><span class="o">.</span><span class="n">HTTPServer</span><span class="p">(</span><span class="n">app</span><span class="p">)</span>  
<span class="n">http_server</span><span class="o">.</span><span class="n">listen</span><span class="p">(</span><span class="n">options</span><span class="o">.</span><span class="n">port</span><span class="p">)</span>
</pre></div>

<p>先是初始化函数  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/tornado-httpserver-init.png" width = "600" height = "400" alt="tornado-httpserver-init" align=center />  </p>

<p>就是简单地初始化一些参数，然后就是父类的初始化。最主要的是这个request_callback，我们传进去的是Application实例，里面有我们自己配制的路由信息，到时候tornado服务器会根据我们的路由信息，将相应的路由请求转发给相应的RequestHandler。  </p>

<p>然后是<code>listen</code>监听，HTTPServer没有覆写父类TCPServer的listen函数，直接看TCPServer的listen：  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/tornado-tcpsever-listen.png" width = "500" height = "200" alt="tornado-tcpserver-listen" align=center />  </p>

<p>先调用了<code>bind_socket</code>，该函数在netutil.py中：  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/netutil-bind_socket.png" width = "550" height = "100" alt="netutil-bind_socket" align=center />  </p>

<p>代码就不看了，功能很简单，我截图了该函数的doc string，根据给定的地址和端口，创建一系列的listening sockets  </p>

<p>之后<code>listen</code>函数调用了<code>self.add_sockets(sockets)</code>，我们来看一下<code>add_sockets</code>：  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/tcpserver-add_sockets.png" width = "650" height = "320" alt="tornado-tcpserver-add_sockets" align=center />  </p>

<p>通过<code>add_accept_handler(sock, self._handle_connection, io_ioop=elf.io_loop)</code>将一系列的listen sockets注册进ioloop（ioloop的作用就是利用epoll，轮询检查所有套接字的io事件，效率很高，是tornado并发量突出的重要原因）  </p>

<p>仔细看一下<code>add_accept_handler()</code>，它在netuilt.py中：  </p>
<div class="highlight"><pre><span class="k">if</span> <span class="n">io_loop</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>  
    <span class="n">io_loop</span> <span class="o">=</span> <span class="n">IOLoop</span><span class="o">.</span><span class="n">current</span><span class="p">()</span>  

<span class="k">def</span> <span class="nf">accept_handler</span><span class="p">(</span><span class="n">fd</span><span class="p">,</span> <span class="n">events</span><span class="p">):</span>  
    <span class="c"># More connections may come in while we&#39;re handling callbacks;  </span>
    <span class="c"># to prevent starvation of other tasks we must limit the number  </span>
    <span class="c"># of connections we accept at a time.  Ideally we would accept  </span>
    <span class="c"># up to the number of connections that were waiting when we  </span>
    <span class="c"># entered this method, but this information is not available  </span>
    <span class="c"># (and rearranging this method to call accept() as many times  </span>
    <span class="c"># as possible before running any callbacks would have adverse  </span>
    <span class="c"># effects on load balancing in multiprocess configurations).  </span>
    <span class="c"># Instead, we use the (default) listen backlog as a rough  </span>
    <span class="c"># heuristic for the number of connections we can reasonably  </span>
    <span class="c"># accept at once.  </span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">_DEFAULT_BACKLOG</span><span class="p">):</span>  
        <span class="k">try</span><span class="p">:</span>  
            <span class="n">connection</span><span class="p">,</span> <span class="n">address</span> <span class="o">=</span> <span class="n">sock</span><span class="o">.</span><span class="n">accept</span><span class="p">()</span>  
        <span class="k">except</span> <span class="n">socket</span><span class="o">.</span><span class="n">error</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>  
            <span class="c"># _ERRNO_WOULDBLOCK indicate we have accepted every  </span>
            <span class="c"># connection that is available.  </span>
            <span class="k">if</span> <span class="n">errno_from_exception</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="ow">in</span> <span class="n">_ERRNO_WOULDBLOCK</span><span class="p">:</span>  
                <span class="k">return</span>  
            <span class="c"># ECONNABORTED indicates that there was a connection  </span>
            <span class="c"># but it was closed while still in the accept queue.  </span>
            <span class="c"># (observed on FreeBSD).  </span>
            <span class="k">if</span> <span class="n">errno_from_exception</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="o">==</span> <span class="n">errno</span><span class="o">.</span><span class="n">ECONNABORTED</span><span class="p">:</span>  
                <span class="k">continue</span>  
            <span class="k">raise</span>  
        <span class="n">callback</span><span class="p">(</span><span class="n">connection</span><span class="p">,</span> <span class="n">address</span><span class="p">)</span>  
<span class="n">io_loop</span><span class="o">.</span><span class="n">add_handler</span><span class="p">(</span><span class="n">sock</span><span class="p">,</span> <span class="n">accept_handler</span><span class="p">,</span> <span class="n">IOLoop</span><span class="o">.</span><span class="n">READ</span><span class="p">)</span>
</pre></div>

<p>利用<code>io_loop.add_handler(sock, accept_handler, IOLoop.READ)</code>，将listen socket注册进ioloop，等待READ事件发生。发生后即回调<code>accept_handler</code>函数，该函数里面有<code>sock.accept()</code>方法，接受客户端连接，之后再调用<code>callback(connection, address)</code>。这里的callback函数就是我们调用<code>add_accept_handler()</code>时候，传进去的<code>self._handle_connection</code>，它的代码在<code>TCPServer</code>中，核心的功能代码内容是  </p>
<div class="highlight"><pre><span class="k">try</span><span class="p">:</span>  
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ssl_options</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>  
        <span class="n">stream</span> <span class="o">=</span> <span class="n">SSLIOStream</span><span class="p">(</span><span class="n">connection</span><span class="p">,</span> <span class="n">io_loop</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">io_loop</span><span class="p">,</span>  
                <span class="n">max_buffer_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_buffer_size</span><span class="p">,</span>  
                <span class="n">read_chunk_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">read_chunk_size</span><span class="p">)</span>  
    <span class="k">else</span><span class="p">:</span>  
        <span class="n">stream</span> <span class="o">=</span> <span class="n">IOStream</span><span class="p">(</span><span class="n">connection</span><span class="p">,</span> <span class="n">io_loop</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">io_loop</span><span class="p">,</span>  
                <span class="n">max_buffer_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_buffer_size</span><span class="p">,</span>  
                <span class="n">read_chunk_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">read_chunk_size</span><span class="p">)</span>  
    <span class="n">future</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">handle_stream</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="n">address</span><span class="p">)</span>  
    <span class="k">if</span> <span class="n">future</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>  
        <span class="bp">self</span><span class="o">.</span><span class="n">io_loop</span><span class="o">.</span><span class="n">add_future</span><span class="p">(</span><span class="n">future</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">f</span><span class="p">:</span> <span class="n">f</span><span class="o">.</span><span class="n">result</span><span class="p">())</span>  
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>  
        <span class="n">app_log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s">&quot;Error in connection callback&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>

<p>为每个connection创建<code>IOStream</code>实例（用于对socket的异步读写），之后的IO操作由此实例负责（其实在IOStream中的读写事件也会注册到ioloop中，后续分析）。然后调用<code>self.handle_stream(stream, address)</code>，<code>handle_stream()</code>由HTTPServer覆写：  </p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">handle_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stream</span><span class="p">,</span> <span class="n">address</span><span class="p">):</span>  
    <span class="n">context</span> <span class="o">=</span> <span class="n">_HTTPRequestContext</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="n">address</span><span class="p">,</span>  
                        <span class="bp">self</span><span class="o">.</span><span class="n">protocol</span><span class="p">)</span>  
    <span class="n">conn</span> <span class="o">=</span> <span class="n">HTTP1ServerConnection</span><span class="p">(</span>  
            <span class="n">stream</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">conn_params</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>  
    <span class="bp">self</span><span class="o">.</span><span class="n">_connections</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">conn</span><span class="p">)</span>  
    <span class="n">conn</span><span class="o">.</span><span class="n">start_serving</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</pre></div>

<p><code>handler_stream</code>创建了HTTPConnection对象，HTTPConnection对象负责处理剩下的交互部分  </p>

<p>ok，HTTPServer大体的核心流程走完了一遍  </p>

<h3>三. 后续</h3>

<p>现在，所有的socket（listen和client）都被注册进了ioloop，它们会被不断地轮询检查，是否有io事件发生。如有读写事件发生，会通过iostream封装的异步READ和WRITE函数进行。HTTPConnection，IOLOOP和IOSTERAM后续再进行分析  </p>

<hr/>

<p>本文参考：<a href="http://www.douban.com/group/topic/13276435/">mywaiting.douban</a>; <a href="kenby.iteye.com/blog/1159621">kenby.iteye</a></p>

            ]]>
        </content>
    </entry>
    
    <entry>
        <title><![CDATA[Unix五种I/O模型对比]]></title>
        <author><name>SuKai</name><uri>http://sukai.me/</uri></author>
        <link href="http://sukai.me/linux-five-io-models/"/>
        <updated>2015-11-04T19:30:00Z</updated>
        <published>2015-11-04T19:30:00Z</published>
        <id>http://sukai.me/linux-five-io-models/</id>
        <content type="html">
            <![CDATA[
             <h3>一. 总览</h3>

<p>先来说一下，<strong>Unix平台有哪几种I/O模型：</strong>  </p>

<ul>
<li>阻塞I/O（blocking I/O）<br/></li>
<li>非阻塞I/O（nonblocking I/O）<br/></li>
<li>I/O多路复用（I/O multiplexing），如select, poll<br/></li>
<li>信号驱动I/O（signal driven I/O），SIGIO<br/></li>
<li>异步I/O（asynchronous I/O），aio POSIX<br/></li>
</ul>

<p>备注：下面介绍各个I/O模型时，会配上一幅示意图，内容是进程进行读取数据操作的请求过程  </p>

<p>需要说明的是，请求进程读取数据的操作时分两步完成的：  </p>

<p>1.等待数据通过网络传输，到达本机内核数据区<br/>
2.将内核数据区的数据拷贝至用户数据区  </p>

<p>之后，程序即可对用户数据区的数据进行业务逻辑操作  </p>

<p>好了，开始了  </p>

<h3>二. 5种I/O模型</h3>

<h4>2.1 blocking I/O</h4>

<p>这个不用多说，最常见的模型。不人为重新设置，socket io默认都是阻塞模式  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/blocking-io.gif" alt="blocking-io"/>  </p>

<p>进程调用了recvfrom，系统不会立即返回，直到数据到达，并成功拷贝至用户区（或者发生一个错误）。之后进程才重新从阻塞状态进入就绪状态  </p>

<h4>2.2 nonblocking I/O</h4>

<p>设置socket为非阻塞模式后，如果I/O操作没有完成，内核不会让该进程进入睡眠状态（即阻塞），而是一直返回一个错误信号（e.g EWOULDBLOCK）  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/nonblocking-io.gif" alt="nonblocking-io"/>  </p>

<p>图片中前三次的recvfrom调用，数据都没有成功返回，而是返回EWOULDBLOCK错误。第四次调用时，数据才准备好。之后，数据被拷贝进用户区，recvfrom调用返回ok  </p>

<p>这种模型的缺点是：应用进程要不断地轮询（polling）内核，查看数据是否到达；这会一直占据CPU，造成浪费  </p>

<p>这种模型不是很常用  </p>

<h4>2.3 I/O multiplexing</h4>

<p>常见的io多路复用的系统调用有select或poll两种  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/io-multiplexing.gif" alt="io-multiplexing"/>  </p>

<p>如图所示：这种模型并没有阻塞在读取I/O操作的系统调用上（e.g recvfrom），而是阻塞在了select(poll)上。等到数据到来，select调用返回，应用程序调用recvfrom将数据从内核区拷贝至用户区进行操作  </p>

<p>仔细看实例图，发现select模型似乎有些disadvantage，即前后进行了两次系统调用，比上一个模型多了一次  </p>

<p>然而，select模型也有其明显的优势：每次select阻塞结束返回后，可以获得多个准备就绪的套接字（即一个select可以对多个套接字进行管理，类似于同时多个监控套接字上的事件是否就绪）  </p>

<p>PS：还有一种与该模型类似的I/O模型：多线程模型。一个线程对应一个套接字，一个线程的阻塞，不影响其他应用  </p>

<h4>2.4 Signal-Driven I/O</h4>

<p>当描述符就绪时，我们可以让内核使用SIGIO信号通知应用程序  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/signal-io.gif" alt=""/>  </p>

<p>首先，我们先得建立一个信号处理者（signal handler），之后程序继续运行干别的事情（此时，并不会阻塞），同时一边等待数据的到达。当数据到达，signal信号激发，之后应用程序可以进行内核区到用户区的数据拷贝（此时是阻塞的），随后进行处理  </p>

<p>该模型的好处就是，等待数据到达前，当前应用线程不会被阻塞  </p>

<h4>2.5 Asynchronous I/O</h4>

<p>AIO是由POSIX标准定义的。它的工作方式是：当所有的I/O操作完成后（包括将数据从内核区复制到用户区），内核再通知应用程序  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/aio.gif" alt="aio"/>  </p>

<p>和signal-driven io不同的是，信号驱动式模型是在数据拷贝前通知应用程序的，这是还未开始真正的I/O操作；而aio是在I/O操作完成时候再进行通知  </p>

<h3>三. 五种I/O模型的比较</h3>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/difference-ios.gif" alt="differnence-between-ios"/>  </p>

<h4>补充：同步I/O和异步I/O</h4>

<ul>
<li>同步I/O：在I/O操作未完成前，请求进程会被阻塞<br/></li>
<li>异步I/O：在I/O操作未完成前，请求进程未会被阻塞<br/></li>
</ul>

<p>上述五种I/O模型，前四种均属于同步I/O，因为recvfrom调用均阻塞了当前请求进程。只有最后一种io属于异步I/O  </p>

<p>我认为，同步与异步的区别在于，数据拷贝时进程是否阻塞；阻塞于非阻塞的区别在于应用程序的调用内核是否立即返回  </p>

<h3>四. 再谈I/O多路复用</h3>

<p>常见的I/O多路复用技术有：  </p>

<ul>
<li>select<br/></li>
<li>poll<br/></li>
</ul>

<p>还有一个高级版本的，叫epoll  </p>

<h4>4.1 select</h4>

<p>select()，确定一个或多个套接口的状态，本函数用于确定一个或多个套接口的状态，对每一个套接口，调用者可查询它的可读性、可写性及错误状态信息，用fd_set结构来表示一组等待检查的套接口，在调用返回时，这个结构存有满足一定条件的套接口组的子集，并且select()返回满足条件的套接口的数目  </p>

<p>其缺点：  </p>

<ul>
<li>每次调用select，先要把fd集合从用户态拷贝到内核态<br/></li>
<li>同时每次调用select都需要在内核遍历传递进来的所有fd；即：每次都会无差别的轮询，即要遍历所有的文件描述符；IO效率随着FD数目增加而线性下降<br/></li>
<li>select所能支持的最多文件描述符数量默认是1024，不是很多<br/></li>
</ul>

<p>Java版本一的NIO库就是利用的select模型，可以参阅我之前的一篇博客<a href="http://sukai.me/java-NIO%E5%88%9D%E6%8E%A2/">“Java NIO初探”</a>  </p>

<h4>4.2 poll</h4>

<p>和select类似  </p>

<p>不同之处在于，描述fd集合的方式不同，poll使用pollfd结构，而不是select的fd_set结构  </p>

<h4>4.3 epoll</h4>

<p>epoll算是I/O多路复用的高级版本，对前两者做了一些改进  </p>

<p>对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。  </p>

<p>对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。  </p>

<p>对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048  </p>

<p>epoll的优点主要是一下几个方面：  </p>

<ul>
<li>IO的效率不会随着监视fd的数量的增长而下降<br/></li>
<li>监视的描述符数量不受限制<br/></li>
</ul>

<p>关于epoll，可以再看看<a href="http://blog.csdn.net/lingfengtengfei/article/details/12398299">CSDN的帖子</a>  </p>

<h4>4.4 比较</h4>

<p>在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知  </p>

<p>这方面的比较，也有一份好帖子，<a href="http://www.cnblogs.com/Anker/p/3265058.html">cnblog</a>  </p>

<hr/>

<p>本文匆忙赶成，错误很多，欢迎纠错  </p>

<p>本文翻译自：<a href="http://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/ch06lev1sec2.html">unix_network_programming</a>  </p>

<hr/>

<h3>参考来源</h3>

<ul>
<li><a href="http://blog.csdn.net/shallwake/article/details/5265287">CSDN</a><br/></li>
<li><a href="http://www.cnblogs.com/Anker/p/3265058.html">cnBlog</a></li>
</ul>

            ]]>
        </content>
    </entry>
    
    <entry>
        <title><![CDATA[多说评论迁移]]></title>
        <author><name>SuKai</name><uri>http://sukai.me/</uri></author>
        <link href="http://sukai.me/doushuo-commment/"/>
        <updated>2015-10-02T15:50:00Z</updated>
        <published>2015-10-02T15:50:00Z</published>
        <id>http://sukai.me/doushuo-commment/</id>
        <content type="html">
            <![CDATA[
             <p>国庆了，放假了，学校人烟稀少  </p>

<p>博客搭建也已经一年多了。之前的博客域名kaiyao.net.cn由于是中国域名，需要备案，也不方便别人记住，就换了一个更个性化的域名：sukai.me，之后就准备一直用这个了。虽然.me域名要贵很多，但算是给自己投资吧，希望我能坚持写博客  </p>

<p>博客迁移，是一件挺麻烦的事情，涉及到文章数据和评论数据。我的博客平台使用的多说评论系统，在我迁移评论的时候，也遇到了一些障碍。但是，最终还是比较完美地迁移成功。讲一下我迁移的方案吧  </p>

<h3>多说评论迁移准备工作</h3>

<p>先去多说后台管理系统，寻找迁移方法。果然，在工具里面找到了<strong>导入数据，导出数据</strong>功能，然后选择<strong>包含评论数据</strong>，并导出评论。之后，会得到一个Json格式的文件  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/多说导入导出数据.png" width = "380" height = "260" alt="多说导入导出数据" align=center />  </p>

<p>导出的json文件没有格式化，随便找个json在线格式化网站，格式化一下，来看看里面是什么内容。我们来选其中一个个体看一下  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/duoshuo-json.png" width = "380" height = "260" alt="json个体" align=center />  </p>

<p>不难读懂：post_id就是这条评论的全局唯一的标识，thread_id是评论所在网页的全局唯一标识（即文章的id），message即具体评论的内容，下面的author_id，author_emial等等就是评论人的相关多说账号信息了  </p>

<p><a href="http://dev.duoshuo.com/docs/500d0629448f04782b00000a">多说文档</a>也是说的明明白白的，结合看一下，一目了然  </p>

<p>ok，当时，心中就大体有方案了  </p>

<h3>多说评论迁移方案</h3>

<p>既然是迁移评论，那么该评论的全局id肯定还是原来的，变的就是文章id了。因为换了新域名嘛，文章id变换了，只要把json文件里面评论的原文章id（就是thread_id）变成相应的新文章id就行啦  </p>

<p>那么，怎么获取新文章的thread_id呢。我当时想到的最笨的方法，去新文章页面下面随便评论一下，从新域名的多说后台系统导出评论数据，打开看一下，thread_id不全都有了吗  </p>

<p>所以，具体的方案就是：从old.com（老域名）的多说后台系统导出评论数据，找到old.com/first-post文章的thread_id；在对应的新文章new.com/first-post下随便评论，导出评论数据，获得新的thread_id；用新id覆盖老id；最后在新域名的博客多说后台系统导入json评论数据就ok了  </p>

<p>亲测可行的  </p>

<p>至于，你想手动覆盖json文件里面的old thread_id，还是写脚本对josn文件操作进行覆盖，看你评论数量而定吧。怎么省事，怎么搞  </p>

<h3>对多说的吐槽</h3>

<p>寻找评论迁移方案的时候，先在多说开发者中心尝试看看能不能找到，结果是没找到。而且，我觉的多说是不是没人维护了？？？很多人在下面提问，就是没有技术支持的回答  </p>

<p>还有，在多说后台管理系统的文章管理页面，多说永远只呈现给我一页的文章数据，甚至有很多内网测试的文章在上面，什么127.0.0.1:8080/first-post这一类。想翻看第二页更多的文章，根本做不到，只有删除第一页文章才行  </p>

<p>我还想换一个评论系统disqus，由于它的加载比较慢，账号不支持国内许多社交账号，还是放弃了  </p>

<p>不得不说，多说成功的原因就是：接天朝地气吧。界面做的也比disqus好看些。接地气，而且好看的东西果然还是很受欢迎的。  </p>

<p>多数的后台数据管理，我就不敢恭维了。估计不止我一个人在吐槽吧  </p>

<p>放假在实验室，没事就喜欢瞎折腾，不写了，国庆快乐啦！  </p>

<hr/>

<p><strong>2015-11-25号更新：</strong>  </p>

<p>多说今天上线新代码，又造成了一大批的用户的bug：  </p>

<p><img src="http://7xl2fd.com1.z0.glb.clouddn.com/duoshuo-bug.png" alt="duoshuo-bug"/>  </p>

<p>11-24号之前的评论在我的站点显示不了。虽然中午12点时，多说称已经修复了bug。我检查了我的站点，发现大部分页面恢复正常，仍有一个页面处于bug中  </p>

<p>搭建博客的意义不应该在于不停地被评论系统所折腾，我决定转到Disqus  </p>

<p>之前的多说评论不想再折腾弄到disqus了，重新开始吧！</p>

            ]]>
        </content>
    </entry>
    
</feed>