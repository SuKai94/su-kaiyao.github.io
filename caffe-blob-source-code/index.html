
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>
Caffe Blob源码阅读 | sukai's blog
</title>
  <link rel="stylesheet" href="http://cdn.amazeui.org/amazeui/2.7.0/css/amazeui.min.css">
  <link rel="stylesheet" href="http://sukai.me/static/css/style.css?v=cca1b84743c64dd398c845a7b968cd30" type="text/css" />
  <!-- <link rel="stylesheet" href="http://sukai.me/static/css/pygments_style.css?v=f52807bdba7d67ebabc3ce287f67bf67" type="text/css" /> -->
</head>

<body>
  <div class="wrapper">
    <!-- header-->
    <header class="header-wrapper">
      <div class="header-container">
        <nav>
          <ul class="header-nav">
            <li><a href="http://sukai.me/"><span class="am-icon-sm am-icon-home" id="nav-icon"></span>Home</a></li>
            <li><a href="http://sukai.me/Board/"><span class="am-icon-sm am-icon-heart" id="nav-icon"></span>Board</a></li>
           <!--  <li><a href="http://sukai.me/MyHistory/"><span class="am-icon-sm am-icon-history" id="nav-icon"></span>TimeLine</a></li> -->
            <li><a href="http://sukai.me/AboutMe/"><span class="am-icon-sm am-icon-user-secret" id="nav-icon"></span>About</a></li>
            <li><a href="http://sukai.me/friend/"><span class="am-icon-sm am-icon-link" id="nav-icon"></span>Links</a></li>
            <li><a href="http://sukai.me/archive/index.html"><span class="am-icon-sm am-icon-archive" id="nav-icon"></span>Archives</a></li>
            <li><a href="http://sukai.me/wiki/"><span class="am-icon-sm am-icon-wikipedia-w" id="nav-icon"></span>Wiki</a></li>
          </ul>
        </nav>
      </div>
    </header>
    <!-- header -->

    <!-- conetent -->
    <div class="content-wrapper">
      <div class="am-g am-g-fixed blog-g-fixed">
        <div class="am-u-md-9">
        
<article class="post-main" id="post-font">
  <header class="blog-header">
    <span class="round-date">
      <span class="month">10月</span>
      <span class="day">31</span>
    </span>
    <p class="blog-title">Caffe Blob源码阅读</p>
    <p class="blog-meta">
      <i class="am-icon-heart-o"></i> Published at Oct 31, 2016 • 
      <!--<i class="am-icon-binoculars"></i> 87 次围观 • -->
      <!--<i class="am-icon-bookmark"></i> 0条评论-->
      <i class="am-icon-tags"></i>
      
        <a class="am-badge am-radius blog-tag" href="http://sukai.me/tag/caffe/">caffe</a>
      
    </p>

  </header>
  <section class="blog-content">
    <p>本文仅用于整理阅读Caffe源码过程中的记录，所写内容只确保本人看懂  </p>

<p>Blob是Caffe中处理和传递实际数据的数据封装包，并且在CPU于GPU之间具有同步处理能力  </p>

<h4>Blob类成员</h4>

<p>Blob是连续存储的N维数组，在 <strong>blob.hpp</strong> 中定义了Blob的成员变量  </p>
<div class="highlight"><pre><span class="nl">protected:</span>  
  <span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">SyncedMemory</span><span class="o">&gt;</span> <span class="n">data_</span><span class="p">;</span>  
  <span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">SyncedMemory</span><span class="o">&gt;</span> <span class="n">diff_</span><span class="p">;</span>  
  <span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">SyncedMemory</span><span class="o">&gt;</span> <span class="n">shape_data_</span><span class="p">;</span> <span class="c1">// 每一维数据的大小  </span>
  <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">shape_</span><span class="p">;</span>  
  <span class="kt">int</span> <span class="n">count_</span><span class="p">;</span> <span class="c1">// 当前容量  </span>
  <span class="kt">int</span> <span class="n">capacity_</span><span class="p">;</span> <span class="c1">// 能承受的容量</span>
</pre></div>

<p>data_ 存储前向传播的数据，diff_ 存储反向传播的梯度；shape_ data_ 和 shape_记录了每一维度数据的大小  </p>

<p>一个Blob最多可以表示 <strong>const int kMaxBlobAxes = 32;</strong> 32维的数组  </p>

<h4>Blob类相关操作</h4>

<p><strong>1.构造函数</strong>  </p>
<div class="highlight"><pre><span class="k">explicit</span> <span class="nf">Blob</span><span class="p">(</span><span class="k">const</span> <span class="kt">int</span> <span class="n">num</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">channels</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">height</span><span class="p">,</span>  
      <span class="k">const</span> <span class="kt">int</span> <span class="n">width</span><span class="p">);</span>  
<span class="k">explicit</span> <span class="nf">Blob</span><span class="p">(</span><span class="k">const</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">shape</span><span class="p">);</span>
</pre></div>

<p>在 <strong>blob.cpp</strong> 中，构造函数会调用 <strong>Reshape</strong> 完成初始化操作，为 data_ 和 diff_ 分配共享内存对象SyncedMemory  </p>
<div class="highlight"><pre><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">Dtype</span><span class="o">&gt;</span>  
<span class="n">Blob</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">&gt;::</span><span class="n">Blob</span><span class="p">(</span><span class="k">const</span> <span class="kt">int</span> <span class="n">num</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">channels</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">height</span><span class="p">,</span>  
    <span class="k">const</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span>  
  <span class="c1">// capacity_ must be initialized before calling Reshape  </span>
  <span class="o">:</span> <span class="n">capacity_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>  
  <span class="n">Reshape</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">);</span>  
<span class="p">}</span>  

<span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">Dtype</span><span class="o">&gt;</span>  
<span class="n">Blob</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">&gt;::</span><span class="n">Blob</span><span class="p">(</span><span class="k">const</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">shape</span><span class="p">)</span>  
  <span class="c1">// capacity_ must be initialized before calling Reshape  </span>
  <span class="o">:</span> <span class="n">capacity_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>  
  <span class="n">Reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">);</span>  
<span class="p">}</span>
</pre></div>

<p><strong>2.Reshape</strong>：修改Blob的大小（尺寸）  </p>
<div class="highlight"><pre><span class="kt">void</span> <span class="nf">Reshape</span><span class="p">(</span><span class="k">const</span> <span class="kt">int</span> <span class="n">num</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">channels</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">height</span><span class="p">,</span>  
      <span class="k">const</span> <span class="kt">int</span> <span class="n">width</span><span class="p">);</span>  
<span class="kt">void</span> <span class="nf">Reshape</span><span class="p">(</span><span class="k">const</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">shape</span><span class="p">);</span>  
<span class="kt">void</span> <span class="nf">Reshape</span><span class="p">(</span><span class="k">const</span> <span class="n">BlobShape</span><span class="o">&amp;</span> <span class="n">shape</span><span class="p">);</span>  
<span class="kt">void</span> <span class="nf">ReshapeLike</span><span class="p">(</span><span class="k">const</span> <span class="n">Blob</span><span class="o">&amp;</span> <span class="n">other</span><span class="p">);</span>
</pre></div>

<p>所有重载Reshape函数最终都调用 void Blob<Dtype>::Reshape(const vector<int>&amp; shape)。特别地，当内存空间不足时(count_ &gt; capacity_)，会为Blob重新分配内存  </p>
<div class="highlight"><pre><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">Dtype</span><span class="o">&gt;</span>  
<span class="kt">void</span> <span class="n">Blob</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">&gt;::</span><span class="n">Reshape</span><span class="p">(</span><span class="k">const</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">shape</span><span class="p">)</span> <span class="p">{</span>  
  <span class="n">CHECK_LE</span><span class="p">(</span><span class="n">shape</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">kMaxBlobAxes</span><span class="p">);</span>  
  <span class="n">count_</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>  
  <span class="n">shape_</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">shape</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>  
  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">shape_data_</span> <span class="o">||</span> <span class="n">shape_data_</span><span class="o">-&gt;</span><span class="n">size</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">shape</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">))</span> <span class="p">{</span>  
    <span class="n">shape_data_</span><span class="p">.</span><span class="n">reset</span><span class="p">(</span><span class="k">new</span> <span class="n">SyncedMemory</span><span class="p">(</span><span class="n">shape</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">)));</span>  
  <span class="p">}</span>  
  <span class="kt">int</span><span class="o">*</span> <span class="n">shape_data</span> <span class="o">=</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">shape_data_</span><span class="o">-&gt;</span><span class="n">mutable_cpu_data</span><span class="p">());</span>  
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">shape</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>  
    <span class="n">CHECK_GE</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">0</span><span class="p">);</span>  
    <span class="k">if</span> <span class="p">(</span><span class="n">count_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>  
      <span class="n">CHECK_LE</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">INT_MAX</span> <span class="o">/</span> <span class="n">count_</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;blob size exceeds INT_MAX&quot;</span><span class="p">;</span>  
    <span class="p">}</span>  
    <span class="n">count_</span> <span class="o">*=</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>  
    <span class="n">shape_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>  
    <span class="n">shape_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>  
  <span class="p">}</span>  
  <span class="k">if</span> <span class="p">(</span><span class="n">count_</span> <span class="o">&gt;</span> <span class="n">capacity_</span><span class="p">)</span> <span class="p">{</span>  
    <span class="n">capacity_</span> <span class="o">=</span> <span class="n">count_</span><span class="p">;</span>  
    <span class="n">data_</span><span class="p">.</span><span class="n">reset</span><span class="p">(</span><span class="k">new</span> <span class="n">SyncedMemory</span><span class="p">(</span><span class="n">capacity_</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">Dtype</span><span class="p">)));</span>  
    <span class="n">diff_</span><span class="p">.</span><span class="n">reset</span><span class="p">(</span><span class="k">new</span> <span class="n">SyncedMemory</span><span class="p">(</span><span class="n">capacity_</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">Dtype</span><span class="p">)));</span>  
  <span class="p">}</span>  
<span class="p">}</span>
</pre></div>

<p><strong>3.offset</strong>用于给定坐标，获取Blob相应坐标数据。例如，对于批量图像数据来说，blob常规的维数为图像数量 N  * 通道数 K * 图像高度 H * 图像宽度 W。Blob按行为主存储。所以4维blob，坐标为（n，k，h，w）的值在blob中的物理位置为（（n * K + k）* H + h）* W + w  </p>
<div class="highlight"><pre><span class="kr">inline</span> <span class="kt">int</span> <span class="nf">offset</span><span class="p">(</span><span class="k">const</span> <span class="kt">int</span> <span class="n">n</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">c</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">h</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>  
      <span class="k">const</span> <span class="kt">int</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>  
    <span class="n">CHECK_GE</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>  
    <span class="n">CHECK_LE</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">num</span><span class="p">());</span>  
    <span class="n">CHECK_GE</span><span class="p">(</span><span class="n">channels</span><span class="p">(),</span> <span class="mi">0</span><span class="p">);</span>  
    <span class="n">CHECK_LE</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">channels</span><span class="p">());</span>  
    <span class="n">CHECK_GE</span><span class="p">(</span><span class="n">height</span><span class="p">(),</span> <span class="mi">0</span><span class="p">);</span>  
    <span class="n">CHECK_LE</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">height</span><span class="p">());</span>  
    <span class="n">CHECK_GE</span><span class="p">(</span><span class="n">width</span><span class="p">(),</span> <span class="mi">0</span><span class="p">);</span>  
    <span class="n">CHECK_LE</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">width</span><span class="p">());</span>  
    <span class="k">return</span> <span class="p">((</span><span class="n">n</span> <span class="o">*</span> <span class="n">channels</span><span class="p">()</span> <span class="o">+</span> <span class="n">c</span><span class="p">)</span> <span class="o">*</span> <span class="n">height</span><span class="p">()</span> <span class="o">+</span> <span class="n">h</span><span class="p">)</span> <span class="o">*</span> <span class="n">width</span><span class="p">()</span> <span class="o">+</span> <span class="n">w</span><span class="p">;</span>  
  <span class="p">}</span>  

  <span class="kr">inline</span> <span class="kt">int</span> <span class="n">offset</span><span class="p">(</span><span class="k">const</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>  
    <span class="n">CHECK_LE</span><span class="p">(</span><span class="n">indices</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">num_axes</span><span class="p">());</span>  
    <span class="kt">int</span> <span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>  
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_axes</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>  
      <span class="n">offset</span> <span class="o">*=</span> <span class="n">shape</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>  
      <span class="k">if</span> <span class="p">(</span><span class="n">indices</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">i</span><span class="p">)</span> <span class="p">{</span>  
        <span class="n">CHECK_GE</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">0</span><span class="p">);</span>  
        <span class="n">CHECK_LT</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">shape</span><span class="p">(</span><span class="n">i</span><span class="p">));</span>  
        <span class="n">offset</span> <span class="o">+=</span> <span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>  
      <span class="p">}</span>  
    <span class="p">}</span>  
    <span class="k">return</span> <span class="n">offset</span><span class="p">;</span>  
  <span class="p">}</span>
</pre></div>

<p><strong>4.Blob的Update</strong>：参数更新操作  </p>

<p>完成梯度下降过程中的参数更新：  </p>

<p>$$data_{k+1} = data_k - diff$$  </p>
<div class="highlight"><pre><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">Dtype</span><span class="o">&gt;</span>  
<span class="kt">void</span> <span class="n">Blob</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">&gt;::</span><span class="n">Update</span><span class="p">()</span> <span class="p">{</span>  
  <span class="c1">// We will perform update based on where the data is located.  </span>
  <span class="k">switch</span> <span class="p">(</span><span class="n">data_</span><span class="o">-&gt;</span><span class="n">head</span><span class="p">())</span> <span class="p">{</span>  
  <span class="k">case</span> <span class="n">SyncedMemory</span>:<span class="o">:</span><span class="n">HEAD_AT_CPU</span><span class="o">:</span>  
    <span class="c1">// perform computation on CPU  </span>
    <span class="n">caffe_axpy</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">&gt;</span><span class="p">(</span><span class="n">count_</span><span class="p">,</span> <span class="n">Dtype</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>  
        <span class="k">static_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="n">Dtype</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">diff_</span><span class="o">-&gt;</span><span class="n">cpu_data</span><span class="p">()),</span>  
        <span class="k">static_cast</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">data_</span><span class="o">-&gt;</span><span class="n">mutable_cpu_data</span><span class="p">()));</span>  
    <span class="k">break</span><span class="p">;</span>  
  <span class="k">case</span> <span class="n">SyncedMemory</span>:<span class="o">:</span><span class="n">HEAD_AT_GPU</span><span class="o">:</span>  
  <span class="k">case</span> <span class="n">SyncedMemory</span>:<span class="o">:</span><span class="n">SYNCED</span><span class="o">:</span>  
<span class="cp">#ifndef CPU_ONLY  </span>
    <span class="c1">// perform computation on GPU  </span>
    <span class="n">caffe_gpu_axpy</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">&gt;</span><span class="p">(</span><span class="n">count_</span><span class="p">,</span> <span class="n">Dtype</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>  
        <span class="k">static_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="n">Dtype</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">diff_</span><span class="o">-&gt;</span><span class="n">gpu_data</span><span class="p">()),</span>  
        <span class="k">static_cast</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">data_</span><span class="o">-&gt;</span><span class="n">mutable_gpu_data</span><span class="p">()));</span>  
<span class="cp">#else  </span>
    <span class="n">NO_GPU</span><span class="p">;</span>  
<span class="cp">#endif  </span>
    <span class="k">break</span><span class="p">;</span>  
  <span class="k">default</span><span class="o">:</span>  
    <span class="n">LOG</span><span class="p">(</span><span class="n">FATAL</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Syncedmem not initialized.&quot;</span><span class="p">;</span>  
  <span class="p">}</span>  
<span class="p">}</span>
</pre></div>

<h4>SyncedMemory类</h4>

<p>Blob中的data 和 diff 既可以存储在CPU上，也可以存储在GPU上。Blob不用去担心数据的分配以及GPU/CPU同步问题，而交由SyncedMemory去管理  </p>

<p>SyncedMemory完成了数据在CPU和GPU上的同步，以及内存的分配和释放操作  </p>

<p>在Blob中访问数据：  </p>

<ul>
<li>一种是以 const 方式只读，不改变数值<br/></li>
<li>一种mutable可改变数值的动态方式<br/></li>
</ul>

<p>最终都是交由 SyncedMemory 的数据访问函数 cpu_data() 和 mutable_cpu_data()  </p>
<div class="highlight"><pre><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">Dtype</span><span class="o">&gt;</span>  
<span class="k">const</span> <span class="n">Dtype</span><span class="o">*</span> <span class="n">Blob</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">&gt;::</span><span class="n">cpu_data</span><span class="p">()</span> <span class="k">const</span> <span class="p">{</span>  
  <span class="n">CHECK</span><span class="p">(</span><span class="n">data_</span><span class="p">);</span>  
  <span class="k">return</span> <span class="p">(</span><span class="k">const</span> <span class="n">Dtype</span><span class="o">*</span><span class="p">)</span><span class="n">data_</span><span class="o">-&gt;</span><span class="n">cpu_data</span><span class="p">();</span>  
<span class="p">}</span>  

<span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">Dtype</span><span class="o">&gt;</span>  
<span class="k">const</span> <span class="n">Dtype</span><span class="o">*</span> <span class="n">Blob</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">&gt;::</span><span class="n">gpu_data</span><span class="p">()</span> <span class="k">const</span> <span class="p">{</span>  
  <span class="n">CHECK</span><span class="p">(</span><span class="n">data_</span><span class="p">);</span>  
  <span class="k">return</span> <span class="p">(</span><span class="k">const</span> <span class="n">Dtype</span><span class="o">*</span><span class="p">)</span><span class="n">data_</span><span class="o">-&gt;</span><span class="n">gpu_data</span><span class="p">();</span>  
<span class="p">}</span>  

<span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">Dtype</span><span class="o">&gt;</span>  
<span class="n">Dtype</span><span class="o">*</span> <span class="n">Blob</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">&gt;::</span><span class="n">mutable_cpu_data</span><span class="p">()</span> <span class="p">{</span>  
  <span class="n">CHECK</span><span class="p">(</span><span class="n">data_</span><span class="p">);</span>  
  <span class="k">return</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">data_</span><span class="o">-&gt;</span><span class="n">mutable_cpu_data</span><span class="p">());</span>  
<span class="p">}</span>  

<span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">Dtype</span><span class="o">&gt;</span>  
<span class="n">Dtype</span><span class="o">*</span> <span class="n">Blob</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">&gt;::</span><span class="n">mutable_gpu_data</span><span class="p">()</span> <span class="p">{</span>  
  <span class="n">CHECK</span><span class="p">(</span><span class="n">data_</span><span class="p">);</span>  
  <span class="k">return</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">data_</span><span class="o">-&gt;</span><span class="n">mutable_gpu_data</span><span class="p">());</span>  
<span class="p">}</span>
</pre></div>

<p>在SyncedMemory中，head_ 表示数据同步状态  </p>
<div class="highlight"><pre><span class="k">enum</span> <span class="n">SyncedHead</span> <span class="p">{</span> <span class="n">UNINITIALIZED</span><span class="p">,</span> <span class="n">HEAD_AT_CPU</span><span class="p">,</span> <span class="n">HEAD_AT_GPU</span><span class="p">,</span> <span class="n">SYNCED</span> <span class="p">};</span>
</pre></div>

<p>并且通过 to_cpu 和 to_gpu 进行数据同步  </p>
<div class="highlight"><pre><span class="kr">inline</span> <span class="kt">void</span> <span class="n">SyncedMemory</span><span class="o">::</span><span class="n">to_cpu</span><span class="p">()</span> <span class="p">{</span>  
  <span class="k">switch</span> <span class="p">(</span><span class="n">head_</span><span class="p">)</span> <span class="p">{</span>  
  <span class="k">case</span> <span class="n">UNINITIALIZED</span>:  
    <span class="n">CaffeMallocHost</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cpu_ptr_</span><span class="p">,</span> <span class="n">size_</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">cpu_malloc_use_cuda_</span><span class="p">);</span>  
    <span class="n">caffe_memset</span><span class="p">(</span><span class="n">size_</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">cpu_ptr_</span><span class="p">);</span>  
    <span class="n">head_</span> <span class="o">=</span> <span class="n">HEAD_AT_CPU</span><span class="p">;</span>  
    <span class="n">own_cpu_data_</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>  
    <span class="k">break</span><span class="p">;</span>  
  <span class="k">case</span> <span class="n">HEAD_AT_GPU</span>:  
<span class="cp">#ifndef CPU_ONLY  </span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cpu_ptr_</span> <span class="o">==</span> <span class="nb">NULL</span><span class="p">)</span> <span class="p">{</span>  
      <span class="n">CaffeMallocHost</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cpu_ptr_</span><span class="p">,</span> <span class="n">size_</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">cpu_malloc_use_cuda_</span><span class="p">);</span>  
      <span class="n">own_cpu_data_</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>  
    <span class="p">}</span>  
    <span class="n">caffe_gpu_memcpy</span><span class="p">(</span><span class="n">size_</span><span class="p">,</span> <span class="n">gpu_ptr_</span><span class="p">,</span> <span class="n">cpu_ptr_</span><span class="p">);</span>  
    <span class="n">head_</span> <span class="o">=</span> <span class="n">SYNCED</span><span class="p">;</span>  
<span class="cp">#else  </span>
    <span class="n">NO_GPU</span><span class="p">;</span>  
<span class="cp">#endif  </span>
    <span class="k">break</span><span class="p">;</span>  
  <span class="k">case</span> <span class="n">HEAD_AT_CPU</span>:  
  <span class="k">case</span> <span class="n">SYNCED</span>:  
    <span class="k">break</span><span class="p">;</span>  
  <span class="p">}</span>  
<span class="p">}</span>  

<span class="kr">inline</span> <span class="kt">void</span> <span class="n">SyncedMemory</span><span class="o">::</span><span class="n">to_gpu</span><span class="p">()</span> <span class="p">{</span>  
<span class="cp">#ifndef CPU_ONLY  </span>
  <span class="k">switch</span> <span class="p">(</span><span class="n">head_</span><span class="p">)</span> <span class="p">{</span>  
  <span class="k">case</span> <span class="n">UNINITIALIZED</span>:  
    <span class="n">CUDA_CHECK</span><span class="p">(</span><span class="n">cudaGetDevice</span><span class="p">(</span><span class="o">&amp;</span><span class="n">gpu_device_</span><span class="p">));</span>  
    <span class="n">CUDA_CHECK</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">gpu_ptr_</span><span class="p">,</span> <span class="n">size_</span><span class="p">));</span>  
    <span class="n">caffe_gpu_memset</span><span class="p">(</span><span class="n">size_</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">gpu_ptr_</span><span class="p">);</span>  
    <span class="n">head_</span> <span class="o">=</span> <span class="n">HEAD_AT_GPU</span><span class="p">;</span>  
    <span class="n">own_gpu_data_</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>  
    <span class="k">break</span><span class="p">;</span>  
  <span class="k">case</span> <span class="n">HEAD_AT_CPU</span>:  
    <span class="k">if</span> <span class="p">(</span><span class="n">gpu_ptr_</span> <span class="o">==</span> <span class="nb">NULL</span><span class="p">)</span> <span class="p">{</span>  
      <span class="n">CUDA_CHECK</span><span class="p">(</span><span class="n">cudaGetDevice</span><span class="p">(</span><span class="o">&amp;</span><span class="n">gpu_device_</span><span class="p">));</span>  
      <span class="n">CUDA_CHECK</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">gpu_ptr_</span><span class="p">,</span> <span class="n">size_</span><span class="p">));</span>  
      <span class="n">own_gpu_data_</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>  
    <span class="p">}</span>  
    <span class="n">caffe_gpu_memcpy</span><span class="p">(</span><span class="n">size_</span><span class="p">,</span> <span class="n">cpu_ptr_</span><span class="p">,</span> <span class="n">gpu_ptr_</span><span class="p">);</span>  
    <span class="n">head_</span> <span class="o">=</span> <span class="n">SYNCED</span><span class="p">;</span>  
    <span class="k">break</span><span class="p">;</span>  
  <span class="k">case</span> <span class="n">HEAD_AT_GPU</span>:  
  <span class="k">case</span> <span class="n">SYNCED</span>:  
    <span class="k">break</span><span class="p">;</span>  
  <span class="p">}</span>  
<span class="cp">#else  </span>
  <span class="n">NO_GPU</span><span class="p">;</span>  
<span class="cp">#endif  </span>
<span class="p">}</span>
</pre></div>

<p>官方有个CPU/GPU数据同步的例子：  </p>
<div class="highlight"><pre><span class="c1">// Assuming that data are on the CPU initially, and we have a blob.  </span>
<span class="k">const</span> <span class="n">Dtype</span><span class="o">*</span> <span class="n">foo</span><span class="p">;</span>  
<span class="n">Dtype</span><span class="o">*</span> <span class="n">bar</span><span class="p">;</span>  
<span class="n">foo</span> <span class="o">=</span> <span class="n">blob</span><span class="p">.</span><span class="n">gpu_data</span><span class="p">();</span> <span class="c1">// data copied cpu-&gt;gpu.  </span>
<span class="n">foo</span> <span class="o">=</span> <span class="n">blob</span><span class="p">.</span><span class="n">cpu_data</span><span class="p">();</span> <span class="c1">// no data copied since both have up-to-date contents.  </span>
<span class="n">bar</span> <span class="o">=</span> <span class="n">blob</span><span class="p">.</span><span class="n">mutable_gpu_data</span><span class="p">();</span> <span class="c1">// no data copied.  </span>
<span class="c1">// ... some operations ...  </span>
<span class="n">bar</span> <span class="o">=</span> <span class="n">blob</span><span class="p">.</span><span class="n">mutable_gpu_data</span><span class="p">();</span> <span class="c1">// no data copied when we are still on GPU.  </span>
<span class="n">foo</span> <span class="o">=</span> <span class="n">blob</span><span class="p">.</span><span class="n">cpu_data</span><span class="p">();</span> <span class="c1">// data copied gpu-&gt;cpu, since the gpu side has modified the data  </span>
<span class="n">foo</span> <span class="o">=</span> <span class="n">blob</span><span class="p">.</span><span class="n">gpu_data</span><span class="p">();</span> <span class="c1">// no data copied since both have up-to-date contents  </span>
<span class="n">bar</span> <span class="o">=</span> <span class="n">blob</span><span class="p">.</span><span class="n">mutable_cpu_data</span><span class="p">();</span> <span class="c1">// still no data copied.  </span>
<span class="n">bar</span> <span class="o">=</span> <span class="n">blob</span><span class="p">.</span><span class="n">mutable_gpu_data</span><span class="p">();</span> <span class="c1">// data copied cpu-&gt;gpu.  </span>
<span class="n">bar</span> <span class="o">=</span> <span class="n">blob</span><span class="p">.</span><span class="n">mutable_cpu_data</span><span class="p">();</span> <span class="c1">// data copied gpu-&gt;cpu.</span>
</pre></div>

<h4>Blob的序列化</h4>

<p>Blob通过Google Protocol Buffers进行相应的序列化操作，相应的函数有  </p>
<div class="highlight"><pre><span class="kt">void</span> <span class="n">Blob</span><span class="o">&lt;</span><span class="n">Dtype</span><span class="o">&gt;::</span><span class="n">FromProto</span><span class="p">(</span><span class="k">const</span> <span class="n">BlobProto</span><span class="o">&amp;</span> <span class="n">proto</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">reshape</span><span class="p">)</span>  
<span class="kt">void</span> <span class="n">Blob</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;::</span><span class="n">ToProto</span><span class="p">(</span><span class="n">BlobProto</span><span class="o">*</span> <span class="n">proto</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">write_diff</span><span class="p">)</span>  
<span class="kt">void</span> <span class="n">Blob</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;::</span><span class="n">ToProto</span><span class="p">(</span><span class="n">BlobProto</span><span class="o">*</span> <span class="n">proto</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">write_diff</span><span class="p">)</span>
</pre></div>

<h4>总结</h4>

<p>Blon详细描述了信息是如何在Layer和Net中存储和交换的，是理解Layer和Net的基础  </p>

<hr/>

<p>References  </p>

<ul>
<li><a href="https://github.com/BVLC/caffe"><a href="https://github.com/BVLC/caffe">https://github.com/BVLC/caffe</a></a><br/></li>
<li><a href="http://imbinwang.github.io/blog/inside-caffe-code-blob" target="_blank"><a href="http://imbinwang.github.io/blog/inside-caffe-code-blob">http://imbinwang.github.io/blog/inside-caffe-code-blob</a></a><br/></li>
</ul>

  </section>
  
    
        
            <div id="disqus_thread"></div>
            <script type="text/javascript">
				var disqus_title = "";
                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = 'http://sukaime.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            </script>
        
        
    

</article>

        </div>

        <div class="sidebar">
          <div class="am-u-md-3">
            <!-- about me -->
            <div class="panel about-me">
              <div class="about-me-bg"></div>
              <div class="about-me-content">
                <a href="http://sukai.me"><img class="avatar" src="http://7xl2fd.com1.z0.glb.clouddn.com/12.png"></img></a>
                <h5 class="about-me-name"><a href="http://sukai.me/AboutMe/">SuKai</a></h5>
                <p class="about-me-words"></p>
                <ul class="about-me-ul">
                  <li class="about-me-li">
                    <a class="about-me-li-content" href="http://sukai.me/archive/index.html">
                      Articles
                      <h5 class="about-me-li-h5">30</h5>
                    </a>
                  </li>
                  <li class="about-me-li">
                    <a class="about-me-li-content" href="http://sukai.me/tag/index.html">
                      Tags
                      <h5 class="about-me-li-h5">35</h5>
                    </a>
                  </li>
                </ul>
              </div>
            </div>
            <!-- about me -->
            
            <!-- contact-me -->
            <div class="contact-me panel-two">
              <h3 class="panel-title">Follow Me</h5>
              <div class="contact-me-icons">
                <a href="https://github.com/su-kaiyao" title="github" target="_blank"><i class="am-icon-github am-icon-md"></i></a>
                <!-- <a href="http://weibo.com/2902370675/profile?topnav=1&wvr=6" target="_blank"><img src="http://7xl2fd.com1.z0.glb.clouddn.com/weibo.png" height="32px" width="32px"></a> -->
                <a href="http://weibo.com/2902370675/profile?topnav=1&wvr=6" title="weibo" target="_blank"><i class="am-icon-weibo am-icon-md"></i></a>
                <a href="https://www.instagram.com/sukai.me/" target="_blank"><img src="http://7xl2fd.com1.z0.glb.clouddn.com/1477079186_Instagram.svg" height="25px" width="25px"></a>
                <a href="https://www.douban.com/people/81024152/" target="_blank"><img src="http://7xl2fd.com1.z0.glb.clouddn.com/douban.png" height="32px" width="32px"></a>
                <!-- <a href="https://twitter.com/SuKai_Coding" title="twitter" target="_blank"><i class="am-icon-twitter am-icon-md"></i></a> -->
                <!-- <a id="weixin-icon">
                  <i class="am-icon-weixin am-icon-md"></i>
                  <div id="weixin-info">
                    <br/>
                    <p>扫扫二维码，多交一枚盆友~</p>
                    <img src="http://7xl2fd.com1.z0.glb.clouddn.com/weixin-qrcode.png">
                  </div>
                </a> -->
              </div>
            </div>
            <!-- contact-me-->
            <!-- email-me -->
            <div class="panel-two">
              <h3 class="panel-title">Contact Me</h5>
              <img src="http://7xl2fd.com1.z0.glb.clouddn.com/sukai.email.gif">
            </div>
            <!-- email-me-->
            <!-- recently -->
            <div class="shuoshuo panel-two">
              <h5 class="panel-title">Tweeting</h5>
              <div class="shuoshuo-content">
                Just keep practicing.
              </div>
              <div class="shuoshuo-content">
                出来混迟早是要还的.
              </div>
            </div>
            <!-- recently -->
            <!-- waiting-->
            <!-- <div class="contact-me panel-two">
              <h3 class="panel-title">Member Of <a target="_blank" href="http://palm.seu.edu.cn/home.html">seu palm</a></h5>
              <span>
                <img id="palm-logo" src="http://7xl2fd.com1.z0.glb.clouddn.com/palm_seu.png">
              </span>
            </div> -->
            
            <!-- Linux Cn -->
            <div class="contact-me panel-two">
              <h3 class="panel-title">Member Of <a target="_blank" href="https://github.com/LCTT">LCTT</a></h5>
              <span>
                <img id="lctt-logo" src="http://7xl2fd.com1.z0.glb.clouddn.com/LCTT.png">
                <a href="http://sukai.me/MyTrans/">Click For More...</a>
              </span>
            </div>
            <!-- Linux Cn -->
            <!--friends -->
            <div class="friends panel-two">
              <h3 class="panel-title">Friends<small><a href="http://sukai.me/friend/">.More</a></small></h5>
              <ul class="friends-ul">
                <li>
                  <a href="http://www.findspace.name/" title="Findspace" target="_blank">Findspace</a>
                </li>
                <li>
                  <a href="http://www.fddcn.cn/" title="奋斗的承诺" target="_blank">奋斗的承诺</a>
                </li>
                <li>
                  <a href="https://www.anotherhome.net/" title="DIYgod" target="_blank">DIYgod</a>
                </li>
                <li>
                  <a href="http://www.llwjy.com/" title="小鸡慢慢" target="_blank">小鸡慢慢</a>
                </li>
                <li>
                  <a href="http://ming.today/" title="Ming YIN" target="_blank">Ming YIN</a>
                </li>
                <li>
                  <a href="http://fuchen.me/" title="ShiFuChen" target="_blank">ShiFuChen</a>
                </li>
                <li>
                  <a href="http://stomach-ache.github.io/" title="Wei Tong" target="_blank">Wei Tong</a>
                </li>
                <li>
                  <a href="http://kirosummer.github.io/" title="Kiro's Blog" target="_blank">Kiro's Blog</a>
                </li>
                <li>
                  <a href="http://www.devchen.com/" title="十七的空指针" target="_blank">十七的空指针</a>
                </li>
                <li>
                  <a href="http://xuweitao.me/" title="肉包子打狗" target="_blank">肉包子打狗</a>
                </li>
                <li>
                  <a href="http://mikecoder.net/" title="MikeCoder's Blog" target="_blank">MikeCoder</a>
                </li>
                <li>
                  <a href="http://iat.net.cn/" title="iat's Blog" target="_blank">iat's Blog</a>
                </li>
                <li>
                  <a href="http://www.renhuanhuan.com/" title="RenHuanHuan's Blog" target="_blank">RenHuanHuan</a>
                </li>
                <li>
                  <a href="http://wanghuanming.com/" title="HuanMing's Blog" target="_blank">HuanMing</a>
                </li>
                <li>
                  <a href="http://maywanting.wang/" title="May's Blog" target="_blank">May's Blog</a>
                </li>
                <li>
                  <a href="http://very9s.net/" title="麻瓜" target="_blank">麻瓜</a>
                </li>
              </ul>
            </div>
            <!--friends -->
            <!-- copyright -->
            <div class="about-copyright panel-two">
              ©Powered by<a href="https://github.com/whtsky/Catsup"> Catsup</a>. Designed by<a href="https://github.com/su-kaiyao/catsup-theme-final"> KaiSu</a>
              <br>
              <img src="http://7xl2fd.com1.z0.glb.clouddn.com/google_analysis.svg" height="15" width="15"/><a href="https://analytics.google.com/" target="_blank"> Google Analysis</a>
            </div>
            <!-- Linux Cn -->
          </div>
        </div>
      </div>
    </div>
    <!-- conetent -->
  </div>

<!--<script src="blog_files/amazeui.js"></script>
<script src="http://lib.sinaapp.com/js/jquery/1.9.1/jquery-1.9.1.min.js"></script>
-->

<!-- <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1257389203'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s4.cnzz.com/z_stat.php%3Fid%3D1257389203' type='text/javascript'%3E%3C/script%3E"));</script> -->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-70406244-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>